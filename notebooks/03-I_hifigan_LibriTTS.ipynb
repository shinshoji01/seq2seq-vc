{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24182e13-4f90-4085-b10d-80dd9894bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import librosa\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"../../cuhksz-phd/sho_util/pyfiles/\")\n",
    "from pytorch import cuda2numpy, cuda2cpu\n",
    "from basic import plot_spectrogram\n",
    "from sound import play_audio\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pyfiles.processsound import trim_audio_and_save\n",
    "\n",
    "import json\n",
    "sys.path.append(\"./../../hifi-gan/\")\n",
    "from meldataset import mel_spectrogram, load_wav\n",
    "from env import AttrDict, build_env\n",
    "config = f'../../hifi-gan/config_16kHz.json'\n",
    "with open(config) as f:\n",
    "    data = f.read()\n",
    "json_config = json.loads(data)\n",
    "h = AttrDict(json_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5ac167f-ef85-423e-adde-2003570acf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_spectrogram(path, MAX_WAV_VALUE=32768.0):\n",
    "    audio, _ = load_wav(path, h.sampling_rate)\n",
    "    if audio.max()>1.0:\n",
    "        audio = audio / MAX_WAV_VALUE\n",
    "    audio = torch.FloatTensor(audio)\n",
    "    audio = audio.unsqueeze(0)\n",
    "    mel = mel_spectrogram(audio, h.n_fft, h.num_mels,\n",
    "                          h.sampling_rate, h.hop_size, h.win_size, h.fmin, h.fmax,\n",
    "                          center=False)\n",
    "    mel = np.array(mel[0])\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "252570ef-9653-4f4c-ace2-b41603d3c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/mntcephfs/lee_dataset/tts/LibriTTS_R/\"\n",
    "# feat_base_dir = \"/mntcephfs/lab_data/shoinoue/Dataset/LibriTTS_R/features/\"\n",
    "feat_base_dir = \"/mntcephfs/data/audiow/shoinoue/Dataset/LibriTTS_R/features/\"\n",
    "fs = 16000\n",
    "\n",
    "speakers = [os.path.basename(a) for a in glob.glob(dataset_dir + \"*/*\")]\n",
    "speakers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16af6b55-0580-4793-914f-0d9c3c5e8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [00:05<00:00, 224.52it/s]\n",
      "  0%|          | 46/160267 [00:03<3:19:10, 13.41it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "tempfile = \"temp3.wav\"\n",
    "trim_threshold_in_db = 30\n",
    "\n",
    "files = []\n",
    "for spk in tqdm(speakers):\n",
    "    files += glob.glob(dataset_dir + f\"*/{spk}/*/*.wav\")\n",
    "files.sort()\n",
    "for path in tqdm(files):\n",
    "    trim_audio_and_save(path, savepath=tempfile, trim_threshold_in_db=trim_threshold_in_db)\n",
    "    mel = get_mel_spectrogram(tempfile)\n",
    "    savepath = feat_base_dir + \"/\".join(path.split(\"/\")[-4:])[:-4] + \"_hifiganmel.npy\"\n",
    "    if save:\n",
    "        np.save(savepath, mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd08a4-73b9-4775-a1ab-a0e4623fbe78",
   "metadata": {},
   "source": [
    " Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d78731b-6f00-4ce1-8c4a-84bdb4f1a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a2a5479-2d35-42e1-b992-2c1d8684bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_name = \"LibriTTS-R_hifiganmel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a73d1afb-5a45-4c87-a2e5-c43afa2b4751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [00:08<00:00, 140.29it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 496.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ckpts/scalers/LibriTTS-R_hifiganmel.save']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "files = []\n",
    "for spk in tqdm(speakers):\n",
    "    files += glob.glob(feat_base_dir + f\"train*/{spk}/*/*_hifiganmel.npy\")\n",
    "files.sort()\n",
    "for path in tqdm(files):\n",
    "    if \"km\" in path:\n",
    "        continue\n",
    "    mel = np.load(path)\n",
    "    scaler.partial_fit(mel.T)\n",
    "            \n",
    "scaler_filename = f\"ckpts/scalers/{scaler_name}.save\"\n",
    "joblib.dump(scaler, scaler_filename) \n",
    "# a = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76380d40-3447-4640-8c92-bd2ed6bddf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
