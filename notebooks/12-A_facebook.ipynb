{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd9f9c4-cc61-4ce9-bb55-230d41c90af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U openai-whisper -i https://mirrors.aliyun.com/pypi/simple/\n",
    "# !pip3 install jiwer -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97faa7e1-5b11-44fc-ba79-692e832df006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/shoinoue/Git/cuhksz-phd/sho_util/pyfiles/\")\n",
    "from sound import play_audio\n",
    "\n",
    "from whisper.normalizers.english import EnglishTextNormalizer\n",
    "normalizer = EnglishTextNormalizer()\n",
    "import jiwer\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "sr = 16000\n",
    "\n",
    "class FacebookASR():\n",
    "    def __init__(self, fs=16000, model_path=\"/mntcephfs/data/audiow/shoinoue/Model/hf_hub/models--facebook--s2t-large-librispeech-asr/snapshots/a4b4750ad1425acda0dbd1daa9188d5fd7872491\"):\n",
    "        self.model = Speech2TextForConditionalGeneration.from_pretrained(model_path).to(\"cuda\")\n",
    "        self.processor = Speech2TextProcessor.from_pretrained(model_path)\n",
    "        self.fs = fs\n",
    "        \n",
    "    def get_sample(self, file):\n",
    "        x, _ = librosa.load(file)\n",
    "        write_wav(\"temp.wav\", self.fs, x)\n",
    "        speech, _ = sf.read(\"temp.wav\")\n",
    "        return speech\n",
    "    \n",
    "    def get_transcription(self, file):\n",
    "        speech = self.get_sample(file)\n",
    "        input_features = self.processor(\n",
    "            speech,\n",
    "            sampling_rate=self.fs,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.cuda()  # Batch size 1\n",
    "        generated_ids = self.model.generate(inputs=input_features)\n",
    "        transcription = self.processor.batch_decode(generated_ids)\n",
    "        return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c21c17-6714-4d1a-972f-0ed92718086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/mntcephfs/lab_data/shoinoue/Dataset/L2-ARCTIC/\"\n",
    "spk = \"ASI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd4018e-3853-438c-8d19-f85fd1c5f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"facebook\": FacebookASR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80eaa1a-3abd-4140-9ac8-c44a2d566dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(base_dir + f\"{spk}/transcript/*\")\n",
    "files.sort()\n",
    "groundtruth_dir = {}\n",
    "for file in files:\n",
    "    f = open(file, \"r\")\n",
    "    text = f.read()\n",
    "    key = os.path.basename(file)[:-4]\n",
    "    groundtruth_dir[key] = normalizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9382bb8-a7d7-4507-88ad-2b767e7de670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1131/1131 [03:05<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "\n",
    "result = {}\n",
    "result[\"predtext\"] = {}\n",
    "result[\"wer\"] = {}\n",
    "audiofiles = glob.glob(base_dir + f\"{spk}/wav/*.wav\")\n",
    "audiofiles.sort()\n",
    "for size in models:\n",
    "    print(size)\n",
    "    model = models[size]\n",
    "    result[\"predtext\"][size] = {}\n",
    "    result[\"wer\"][size] = {}\n",
    "    for file in tqdm(audiofiles):\n",
    "        key = os.path.basename(file)[:-4]\n",
    "        predtext = normalizer(models[size].get_transcription(file)[0])\n",
    "        result[\"predtext\"][size][key] = predtext\n",
    "        wer = jiwer.wer(groundtruth_dir[key], [predtext])\n",
    "        result[\"wer\"][size][key] = wer\n",
    "            \n",
    "savefile = \"./wer_facebook_result.npy\"\n",
    "if save:\n",
    "    np.save(savefile, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18ba93-d76f-440e-b414-5a054c7d5998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802ad25-2944-437f-80d4-2194ab572bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
