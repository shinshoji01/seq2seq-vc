{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24182e13-4f90-4085-b10d-80dd9894bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "import torchaudio\n",
    "from speechbrain.pretrained.interfaces import foreign_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e60fb7-6e58-4b58-a744-9b6f77a9c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "speechbrain.lobes.models.huggingface_wav2vec - wav2vec 2.0 is frozen.\n"
     ]
    }
   ],
   "source": [
    "classifier = foreign_class(source=\"/mntcephfs/lab_data/shoinoue/Models/trained_models/accent/CustomEncoderWav2vec2Classifier-a72df039c801fa14a1c3226e95ab8c14/\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\", savedir=\"/mntcephfs/lab_data/shoinoue/Models/trained_models/accent/CustomEncoderWav2vec2Classifier-a72df039c801fa14a1c3226e95ab8c14/\", run_opts={\"device\":\"cuda\"})\n",
    "accents = [\"us\", \"england\", \"australia\", \"indian\", \"canada\", \"bermuda\", \"scotland\", \"african\", \"ireland\", \"newzealand\", \"wales\", \"malaysia\", \"philippines\", \"singapore\", \"hongkong\", \"southatlandtic\",]\n",
    "\n",
    "tempfile = \"temp.wav\"\n",
    "def run_classification(path):\n",
    "    audio, _ = librosa.load(path, sr=fs)\n",
    "    torchaudio.save(tempfile, torch.tensor(audio).unsqueeze(0), fs)\n",
    "    signal, org_sr = torchaudio.load(tempfile)\n",
    "    signal = torchaudio.functional.resample(signal, orig_freq=org_sr, new_freq=fs)\n",
    "    outputs =  classifier.encode_batch(signal)\n",
    "    embeddings =  outputs[0].detach().cpu().numpy()\n",
    "    outputs = classifier.mods.output_mlp(outputs)\n",
    "    rawaccent = outputs[0].detach().cpu().numpy()\n",
    "    probaccent = classifier.hparams.softmax(outputs).detach().cpu().numpy()[0]\n",
    "    return embeddings, rawaccent, probaccent\n",
    "\n",
    "def cosine_similarity(e1, e2): # from wespeaker, delete the normalizing part\n",
    "    e1 = torch.tensor(e1)\n",
    "    e2 = torch.tensor(e2)\n",
    "    cosine_score = torch.dot(e1, e2) / (torch.norm(e1) * torch.norm(e2))\n",
    "    cosine_score = cosine_score.item()\n",
    "    return cosine_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6c1430-a092-43bf-b801-0383bc5012a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "accent_dir = \"/mntcephfs/lab_data/shoinoue/Dataset/PD-AST/SLT/Hindi/wav/\"\n",
    "native_dir = \"/mntcephfs/lab_data/shoinoue/Dataset/PD-AST/SLT/English/wav/\"\n",
    "base_model_dir = \"/mntcephfs/lab_data/shoinoue/Models/trained_models/AC_01/ckpts_16000/\"\n",
    "model_paths = [\n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_melmel_hubert_norepeating_smaller/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_melmel_hubert_norepeating_small/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_melmel_hubert_norepeating/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_melmel_hubert_norepeating_smaller/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_melmel_hubert_norepeating_small/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_melmel_hubert_norepeating/100000\",\n",
    "    \n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_80mel80mel_hubert_norepeating_smaller/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_80mel80mel_hubert_norepeating_small/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_80mel80mel_hubert_norepeating/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_80mel80mel_hubert_norepeating_smaller/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_80mel80mel_hubert_norepeating_small/100000\",\n",
    "#     \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_80mel80mel_hubert_norepeating/100000\",\n",
    "    \n",
    "#     \"VTN_fine-tuning_nocondition_gt2syn_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "    \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "]\n",
    "base_dataset_dir = \"/mntcephfs/lab_data/shoinoue/Dataset/\"\n",
    "dataset_paths = [\n",
    "    # \"PD-AST/SLT/English\",\n",
    "    # \"PD-AST/SLT/Hindi\",\n",
    "    # \"PD-AST/SLT/Korean\",\n",
    "    # \"PD-AST/ASI/Hindi\",\n",
    "    # \"PD-AST/TNI/Hindi\",\n",
    "    # \"PD-AST/HKK/Korean\",\n",
    "    # \"PD-AST/YDCK/Korean\",\n",
    "    # \"CMU-ARCTIC/SLT\",\n",
    "    # \"L2-ARCTIC/ASI\",\n",
    "    # \"L2-ARCTIC/TNI\",\n",
    "    # \"L2-ARCTIC/HKK\",\n",
    "    # \"L2-ARCTIC/YDCK\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed217a45-64eb-4585-bce9-ba43aa7dc4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTN_fine-tuning_nocondition_mix2synVCTK3hr_hifiganmelhifiganmel_hubert_norepeating/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.59it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = f\"evaluation/accent/\"\n",
    "testsamples = list(np.load(\"data_split_ARCTIC.npy\", allow_pickle=True))[2]\n",
    "for ij in range(2):\n",
    "    base_dir = [base_model_dir, base_dataset_dir][ij]\n",
    "    dirnames = [model_paths, dataset_paths][ij]\n",
    "    for dirname in dirnames:\n",
    "        save_path = save_dir + f'{\"___\".join(dirname.split(\"/\"))}.npy'\n",
    "        # if os.path.exists(save_path):\n",
    "            # continue\n",
    "        print(dirname)\n",
    "        files = glob.glob(base_dir + f\"{dirname}/wav/*.wav\")\n",
    "        files.sort()\n",
    "        raws, probs, embs = [], [], []\n",
    "        for path in tqdm(files):\n",
    "            basename = os.path.basename(path)[:-4]\n",
    "            if not(basename in testsamples):\n",
    "                continue\n",
    "            accent_path = f\"./evaluation/accent_embeddings/Hindi/{basename}.npy\"\n",
    "            native_path = f\"./evaluation/accent_embeddings/English/{basename}.npy\"\n",
    "            accent = np.load(accent_path, allow_pickle=True).item()\n",
    "            native = np.load(native_path, allow_pickle=True).item()\n",
    "            \n",
    "            embeddings, rawaccent, probaccent = run_classification(path)\n",
    "            a = cosine_similarity(embeddings, accent[\"embeddings\"])\n",
    "            b = cosine_similarity(embeddings, native[\"embeddings\"])\n",
    "            diff = a-b\n",
    "            raws += [rawaccent[3]]\n",
    "            probs += [probaccent[3]]\n",
    "            embs += [diff]\n",
    "            # if len(embs)>5:\n",
    "            #     break\n",
    "\n",
    "        # np.save(save_path, [raws, probs, embs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
