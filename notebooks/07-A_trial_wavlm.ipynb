{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156a34a3-b3c2-475f-bdc7-5d859d259cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./../../unilm/wavlm/\")\n",
    "from WavLM import WavLM, WavLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9abf66-8d5b-44d0-813b-5eec76cdc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "ckpt_path = \"/mntcephfs/lab_data/shoinoue/Models/trained_models/wavlm/WavLM-Large.pt\"\n",
    "\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "cfg = WavLMConfig(checkpoint['cfg'])\n",
    "model = WavLM(cfg)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7bdd5d-55ff-4741-8e6e-2d0a698e1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavLMExtractor():\n",
    "    def __init__(self, fs=16000, ckpt_path=\"/mntcephfs/lab_data/shoinoue/Models/trained_models/wavlm/WavLM-Large.pt\", device=\"cuda\"):\n",
    "        self.fs = fs\n",
    "        checkpoint = torch.load(ckpt_path)\n",
    "        cfg = WavLMConfig(checkpoint['cfg'])\n",
    "        model = WavLM(cfg)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        model.eval();\n",
    "        self.model = model.to(device)\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "    \n",
    "    def get_feature(self, path):\n",
    "        wav, _ = librosa.load(path, self.fs)\n",
    "        wav_input_16khz = torch.tensor(wav).unsqueeze(0)\n",
    "        if self.cfg.normalize:\n",
    "            wav_input_16khz = torch.nn.functional.layer_norm(wav_input_16khz , wav_input_16khz.shape)\n",
    "        rep = self.model.extract_features(wav_input_16khz.to(self.device))[0][0]\n",
    "        return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b81e0a-6eb3-46b4-91e0-16711cfb5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mntcephfs/lab_data/shoinoue/Dataset/L2-ARCTIC/HKK/wav/arctic_a0001.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54dd4f13-4101-41f9-91c1-48b27b8a7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavlm = WavLMExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28fb60c2-a6fd-4f79-988b-8f5fff0827eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([179, 1024])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavlm.get_feature(path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6637fd5-d7a8-425e-bd9c-ad433507bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the representation of last layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af27511-9159-4468-95a7-38c369a1c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0630,  0.1153, -0.1073,  ..., -0.0424,  0.3143, -0.2737],\n",
       "        [ 0.1324,  0.0528, -0.2474,  ...,  0.1291,  0.0365, -0.1063],\n",
       "        [ 0.1097, -0.0708, -0.0916,  ...,  0.1428, -0.0264,  0.2364],\n",
       "        ...,\n",
       "        [ 0.0769,  0.2265,  0.0669,  ..., -0.0678,  0.0518,  0.1354],\n",
       "        [-0.0420,  0.1428,  0.0902,  ..., -0.1188,  0.0996,  0.2102],\n",
       "        [-0.2314, -0.0065,  0.1919,  ...,  0.0016,  0.1852,  0.0608]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ecd96f-0b6f-4f99-98e9-00b9303c7139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098c34c2-d5a6-4b7b-9e2d-50bd36bda735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-35.3634,  28.3430, -93.9248,  ..., -63.4952,  60.0124,  18.8887],\n",
       "         [ -1.6355,  40.0090, -85.3306,  ..., -64.3624,  33.2331, -28.8264],\n",
       "         [-10.1995,  33.1479, -71.1561,  ..., -67.3214,  24.3543, -33.4058],\n",
       "         ...,\n",
       "         [-72.8382,  33.7898,   5.8237,  ..., -71.1066, -19.8455, -42.0761],\n",
       "         [-66.8966,  33.8302,   5.1525,  ..., -76.2053, -11.9666, -53.3977],\n",
       "         [-78.6402,  18.9396, -19.4920,  ..., -38.9124,  18.8453,  -7.0787]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da897a9-06ea-4dbd-903b-363a6521a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605636b-f2cb-4ac6-b301-a96cb1adc20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
