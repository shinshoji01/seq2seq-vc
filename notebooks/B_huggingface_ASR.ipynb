{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3a7b56-b8a7-4f57-a103-0aee2de7a209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/shoinoue/Git/cuhksz-phd/sho_util/pyfiles/\")\n",
    "from sound import play_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd21723-bd46-44d8-a3ce-138759f4b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/mntcephfs/data/audiow/shoinoue/Model/hf_hub/models--facebook--s2t-large-librispeech-asr/snapshots/a4b4750ad1425acda0dbd1daa9188d5fd7872491\"\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(model_path).to(\"cuda\")\n",
    "processor = Speech2TextProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85ce9cbf-77d9-4243-ab36-f1450b4b8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacebookASR():\n",
    "    def __init__(self, fs=16000, model_path=\"/mntcephfs/data/audiow/shoinoue/Model/hf_hub/models--facebook--s2t-large-librispeech-asr/snapshots/a4b4750ad1425acda0dbd1daa9188d5fd7872491\"):\n",
    "        self.model = Speech2TextForConditionalGeneration.from_pretrained(model_path).to(\"cuda\")\n",
    "        self.processor = Speech2TextProcessor.from_pretrained(model_path)\n",
    "        self.fs = fs\n",
    "        \n",
    "    def get_sample(self, file):\n",
    "        x, _ = librosa.load(file)\n",
    "        write_wav(\"temp.wav\", self.fs, x)\n",
    "        speech, _ = sf.read(\"temp.wav\")\n",
    "        return speech\n",
    "    \n",
    "    def get_transcription(self, file):\n",
    "        speech = self.get_sample(file)\n",
    "        input_features = self.processor(\n",
    "            speech,\n",
    "            sampling_rate=self.fs,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.cuda()  # Batch size 1\n",
    "        generated_ids = self.model.generate(inputs=input_features)\n",
    "        transcription = self.processor.batch_decode(generated_ids)\n",
    "        return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4425e-4bf4-4ab9-b60e-48e21c850f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1f69d5-98d3-42fc-bb53-1ffa50445096",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/mntcephfs/lab_data/shoinoue/Dataset/L2-ARCTIC/ASI/wav/arctic_b0539.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db698c0-73f1-434c-9411-84a6223a09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io.wavfile import write as write_wav\n",
    "import librosa\n",
    "\n",
    "def get_sample(file, fs=16000):\n",
    "    x, _ = librosa.load(file)\n",
    "    write_wav(\"temp.wav\", fs, x)\n",
    "    speech, _ = sf.read(\"temp.wav\")\n",
    "    return speech\n",
    "\n",
    "speech = get_sample(file)\n",
    "input_features = processor(\n",
    "    speech,\n",
    "    sampling_rate=16_000,\n",
    "    return_tensors=\"pt\"\n",
    ").input_features.cuda()  # Batch size 1\n",
    "generated_ids = model.generate(inputs=input_features)\n",
    "transcription = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161131b9-aba3-4b2e-a82c-0c439c28fc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you were making them talk sharp ruth charged him']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "raw",
   "id": "757ddaee-ae7c-4fde-9bbb-5ea13ccc4d9c",
   "metadata": {},
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"patrickvonplaten/librispeech_asr_dummy\",\n",
    "    \"clean\",\n",
    "    split=\"validation\",\n",
    "    cache_dir=\"/mntcephfs/data/audiow/shoinoue/Model/hf_hub/\",\n",
    ")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_features = processor(\n",
    "    ds[\"speech\"][0],\n",
    "    sampling_rate=16_000,\n",
    "    return_tensors=\"pt\"\n",
    ").input_features  # Batch size 1\n",
    "generated_ids = model.generate(input_ids=input_features)\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9862b63-ec0e-4ba3-b7ca-af3209060841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
