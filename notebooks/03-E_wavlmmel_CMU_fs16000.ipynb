{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9314689b-e757-45b5-9af9-7bf79380924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa==0.9.0 -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24182e13-4f90-4085-b10d-80dd9894bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import torchaudio\n",
    "import tgt\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pyfiles.feature_extractor import WavLMExtractor\n",
    "from vocos.feature_extractors import MelSpectrogramFeatures\n",
    "\n",
    "sys.path.append(\"../../cuhksz-phd/sho_util/pyfiles\")\n",
    "from sound import play_audio\n",
    "from basic import plot_spectrogram\n",
    "\n",
    "def trim_audio_and_save(path, fs=16000, savepath=\"temp.wav\", trim_threshold_in_db=30, trim_frame_size=2048, trim_hop_size=512):\n",
    "    audio, _ = librosa.load(path, sr=fs)\n",
    "    audio, _ = librosa.effects.trim(\n",
    "        audio,\n",
    "        top_db=trim_threshold_in_db,\n",
    "        frame_length=trim_frame_size,\n",
    "        hop_length=trim_hop_size,\n",
    "    )\n",
    "    torchaudio.save(savepath, torch.tensor(audio).unsqueeze(0), fs)\n",
    "    return \n",
    "def get_mel(path):\n",
    "    y, sr = torchaudio.load(path)\n",
    "    if fs!=sr:\n",
    "        if y.size(0) > 1:  # mix to mono\n",
    "            y = y.mean(dim=0, keepdim=True)\n",
    "        y = torchaudio.functional.resample(y, orig_freq=sr, new_freq=fs)\n",
    "    mel = melgen(y[0])\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3162a69-4fe6-4fb8-b0c3-c62c22af1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/mntcephfs/lab_data/shoinoue/\"\n",
    "dataset_dir = data_dir + \"Dataset/CMU-ARCTIC/\"\n",
    "fs = 16000\n",
    "trim_threshold_in_db = 30\n",
    "\n",
    "melgen = MelSpectrogramFeatures(sample_rate=fs)\n",
    "wavlm = WavLMExtractor()\n",
    "speakers = [os.path.basename(a) for a in glob.glob(dataset_dir + \"*\")]\n",
    "speakers.remove(\"SLT\")\n",
    "speakers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d5ced97-4af6-41cd-9b5f-652db86a41d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BDL']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73cb83c2-94d9-498c-8937-52a872e8d33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1132/1132 [00:42<00:00, 26.61it/s]\n"
     ]
    }
   ],
   "source": [
    "save = True\n",
    "tempfile = \"temp.wav\"\n",
    "\n",
    "for spk in speakers:\n",
    "    print(spk)\n",
    "    wavlm_dir = f\"{dataset_dir}{spk}/wavlm/\"\n",
    "    mel_dir = f\"{dataset_dir}{spk}/mel/\"\n",
    "    os.makedirs(wavlm_dir, exist_ok=True)\n",
    "    os.makedirs(mel_dir, exist_ok=True)\n",
    "    filenames = glob.glob(dataset_dir + spk + \"/wav/*\")\n",
    "    filenames.sort()\n",
    "    for path in tqdm(filenames):\n",
    "        trim_audio_and_save(path, savepath=tempfile, trim_threshold_in_db=trim_threshold_in_db)\n",
    "        \n",
    "        # wavlm\n",
    "        embedding = wavlm.get_feature(tempfile).T.detach().cpu().numpy()\n",
    "        savepath = wavlm_dir + os.path.basename(path)[:-4] + \".npy\"\n",
    "        if save:\n",
    "            np.save(savepath, embedding)\n",
    "            \n",
    "        # mel\n",
    "        mel = get_mel(tempfile)\n",
    "        savepath = mel_dir + os.path.basename(path)[:-4] + \".npy\"\n",
    "        if save:\n",
    "            np.save(savepath, mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dafe0e1-ca21-444e-a1e4-2d761f4da747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa44cd84-3bdc-44d2-a705-3b5a849c94f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mntcephfs/lab_data/shoinoue/Dataset/CMU-ARCTIC/SLT/mel/arctic_a0152.npy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f7c40-9c0f-4b64-8a45-38dc31a51a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "cfafce97-d8c8-4d0a-b668-0d62c38a190d",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "path = filenames[11]\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "audio, _ = librosa.load(path, sr=fs)\n",
    "torchaudio.save(\"temp.wav\", torch.tensor(audio).unsqueeze(0), fs)\n",
    "mel = np.array(get_mel(\"temp.wav\"))\n",
    "print(mel.shape)\n",
    "play_audio(\"temp.wav\", fs)\n",
    "plot_spectrogram(mel, fig, (1, 2, 1))\n",
    "\n",
    "trim_audio_and_save(path)\n",
    "mel = np.array(get_mel(\"temp.wav\"))\n",
    "print(mel.shape)\n",
    "play_audio(\"temp.wav\", fs)\n",
    "plot_spectrogram(mel, fig, (1, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd08a4-73b9-4775-a1ab-a0e4623fbe78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
