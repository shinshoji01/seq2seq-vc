{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14ae1fd-ea23-4724-b100-8c789924c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pyfiles.dataset import PretrainingMelDataset\n",
    "\n",
    "import seq2seq_vc\n",
    "import seq2seq_vc.models\n",
    "import seq2seq_vc.losses\n",
    "import seq2seq_vc.trainers\n",
    "import seq2seq_vc.collaters\n",
    "\n",
    "# from seq2seq_vc.datasets import ParallelVCMelDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from seq2seq_vc.utils import read_hdf5\n",
    "from seq2seq_vc.utils.types import str_or_none\n",
    "\n",
    "# set to avoid matplotlib error in CLI environment\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seq2seq_vc.schedulers.warmup_lr import WarmupLR\n",
    "\n",
    "scheduler_classes = dict(warmuplr=WarmupLR)\n",
    "\n",
    "class Dict2Obj(object):\n",
    "    def __init__(self, dictionary):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        for key in dictionary:\n",
    "            setattr(self, key, dictionary[key])\n",
    "\n",
    "import joblib\n",
    "import glob\n",
    "datasplit = list(np.load(\"./data_split_ARCTIC.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5364a0c2-a2dd-4265-a3e9-f52890493e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Variables\n",
    "dataset_dir = \"/mntcephfs/lee_dataset/tts/LibriTTS_R/\"\n",
    "feat_base_dir = \"/mntcephfs/lab_data/shoinoue/Dataset/LibriTTS_R/features/\"\n",
    "\n",
    "scaler = {}\n",
    "scaler_filename = f\"ckpts/scalers/LibriTTS-R_16000.save\"\n",
    "scaler[\"mel\"] = joblib.load(scaler_filename)\n",
    "scaler_filename = f\"ckpts/scalers/LibriTTS-R_wavlm.save\"\n",
    "scaler[\"wavlm\"] = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64ecf55-0e57-4891-9c20-68169f2224c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/mntcephfs/lab_data/shoinoue/Models/trained_models/AC_01/ckpts_16000/pretraining_nocondition_LibriTTS-R_hubertmel_small/checkpoint-500000steps.pkl\"\n",
    "\n",
    "input_type = \"mel\"\n",
    "inputoutput = [input_type, \"mel\"] # mel to mimic wavlm\n",
    "if \"smaller\" in checkpoint_path:\n",
    "    size = \"smaller\"\n",
    "elif \"small\" in checkpoint_path:\n",
    "    size = \"small\"\n",
    "else:\n",
    "    size = \"\"\n",
    "if \"addition\" in checkpoint_path:\n",
    "    conditiontype = \"add\"\n",
    "elif \"concatenation\" in checkpoint_path:\n",
    "    conditiontype = \"concat\"\n",
    "elif \"nocondition\" in checkpoint_path:\n",
    "    conditiontype = \"nocondition\"\n",
    "\n",
    "args = {}\n",
    "args[\"rank\"] = 0\n",
    "args[\"outdir\"] = f\"/mntcephfs/lab_data/shoinoue/Models/trained_models/AC_01/ckpts_16000/encoder_fine-tuning_{conditiontype}_{''.join(inputoutput)}_fromhubert_{size}/\"\n",
    "args[\"config_path\"] = f\"./../egs/l2-arctic/cascade/conf/{size}m2mvtn.{''.join(inputoutput)}.yaml\"\n",
    "args[\"init_checkpoint\"] = checkpoint_path\n",
    "args[\"resume\"] = \"\"\n",
    "args[\"distributed\"] = False\n",
    "args = Dict2Obj(args)\n",
    "\n",
    "# load main config\n",
    "with open(args.config_path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "config.update(vars(args))\n",
    "\n",
    "config[\"model_params\"][\"conditiontype\"] = conditiontype\n",
    "config[\"init-mods\"] = [\"decoder\", \"feat_out\", \"prob_out\", \"postnet\"]\n",
    "config[\"freeze-mods\"] = [\"decoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73d4fbe-2fe1-4791-832a-8cbbc6e37984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Overriding module decoder.embed.0.0.prenet.0.0.weight\n",
      "WARNING:root:Overriding module decoder.embed.0.0.prenet.0.0.bias\n",
      "WARNING:root:Overriding module decoder.embed.0.0.prenet.1.0.weight\n",
      "WARNING:root:Overriding module decoder.embed.0.0.prenet.1.0.bias\n",
      "WARNING:root:Overriding module decoder.embed.0.1.weight\n",
      "WARNING:root:Overriding module decoder.embed.0.1.bias\n",
      "WARNING:root:Overriding module decoder.embed.1.alpha\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.self_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.src_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.feed_forward.w_1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.feed_forward.w_1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.feed_forward.w_2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.feed_forward.w_2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.norm1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.norm1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.norm2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.norm2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.0.norm3.weight\n",
      "WARNING:root:Overriding module decoder.decoders.0.norm3.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.self_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.src_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.feed_forward.w_1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.feed_forward.w_1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.feed_forward.w_2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.feed_forward.w_2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.norm1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.norm1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.norm2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.norm2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.1.norm3.weight\n",
      "WARNING:root:Overriding module decoder.decoders.1.norm3.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.self_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.src_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.feed_forward.w_1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.feed_forward.w_1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.feed_forward.w_2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.feed_forward.w_2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.norm1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.norm1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.norm2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.norm2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.2.norm3.weight\n",
      "WARNING:root:Overriding module decoder.decoders.2.norm3.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.self_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.src_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.feed_forward.w_1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.feed_forward.w_1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.feed_forward.w_2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.feed_forward.w_2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.norm1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.norm1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.norm2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.norm2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.3.norm3.weight\n",
      "WARNING:root:Overriding module decoder.decoders.3.norm3.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.self_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.src_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.feed_forward.w_1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.feed_forward.w_1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.feed_forward.w_2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.feed_forward.w_2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.norm1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.norm1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.norm2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.norm2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.4.norm3.weight\n",
      "WARNING:root:Overriding module decoder.decoders.4.norm3.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.self_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_q.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_q.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_k.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_k.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_v.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_v.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_out.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.src_attn.linear_out.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.feed_forward.w_1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.feed_forward.w_1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.feed_forward.w_2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.feed_forward.w_2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.norm1.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.norm1.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.norm2.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.norm2.bias\n",
      "WARNING:root:Overriding module decoder.decoders.5.norm3.weight\n",
      "WARNING:root:Overriding module decoder.decoders.5.norm3.bias\n",
      "WARNING:root:Overriding module feat_out.weight\n",
      "WARNING:root:Overriding module feat_out.bias\n",
      "WARNING:root:Overriding module prob_out.weight\n",
      "WARNING:root:Overriding module prob_out.bias\n",
      "WARNING:root:Overriding module postnet.postnet.0.0.weight\n",
      "WARNING:root:Overriding module postnet.postnet.0.1.weight\n",
      "WARNING:root:Overriding module postnet.postnet.0.1.bias\n",
      "WARNING:root:Overriding module postnet.postnet.0.1.running_mean\n",
      "WARNING:root:Overriding module postnet.postnet.0.1.running_var\n",
      "WARNING:root:Overriding module postnet.postnet.0.1.num_batches_tracked\n",
      "WARNING:root:Overriding module postnet.postnet.1.0.weight\n",
      "WARNING:root:Overriding module postnet.postnet.1.1.weight\n",
      "WARNING:root:Overriding module postnet.postnet.1.1.bias\n",
      "WARNING:root:Overriding module postnet.postnet.1.1.running_mean\n",
      "WARNING:root:Overriding module postnet.postnet.1.1.running_var\n",
      "WARNING:root:Overriding module postnet.postnet.1.1.num_batches_tracked\n",
      "WARNING:root:Overriding module postnet.postnet.2.0.weight\n",
      "WARNING:root:Overriding module postnet.postnet.2.1.weight\n",
      "WARNING:root:Overriding module postnet.postnet.2.1.bias\n",
      "WARNING:root:Overriding module postnet.postnet.2.1.running_mean\n",
      "WARNING:root:Overriding module postnet.postnet.2.1.running_var\n",
      "WARNING:root:Overriding module postnet.postnet.2.1.num_batches_tracked\n",
      "WARNING:root:Overriding module postnet.postnet.3.0.weight\n",
      "WARNING:root:Overriding module postnet.postnet.3.1.weight\n",
      "WARNING:root:Overriding module postnet.postnet.3.1.bias\n",
      "WARNING:root:Overriding module postnet.postnet.3.1.running_mean\n",
      "WARNING:root:Overriding module postnet.postnet.3.1.running_var\n",
      "WARNING:root:Overriding module postnet.postnet.3.1.num_batches_tracked\n",
      "WARNING:root:Overriding module postnet.postnet.4.0.weight\n",
      "WARNING:root:Overriding module postnet.postnet.4.1.weight\n",
      "WARNING:root:Overriding module postnet.postnet.4.1.bias\n",
      "WARNING:root:Overriding module postnet.postnet.4.1.running_mean\n",
      "WARNING:root:Overriding module postnet.postnet.4.1.running_var\n",
      "WARNING:root:Overriding module postnet.postnet.4.1.num_batches_tracked\n",
      "WARNING:root:Freezing decoder.embed.0.0.prenet.0.0.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.embed.0.0.prenet.0.0.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.embed.0.0.prenet.1.0.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.embed.0.0.prenet.1.0.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.embed.0.1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.embed.0.1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.embed.1.alpha. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.self_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.src_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.feed_forward.w_1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.feed_forward.w_1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.feed_forward.w_2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.feed_forward.w_2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.norm1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.norm1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.norm2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.norm2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.norm3.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.0.norm3.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.self_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.src_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.feed_forward.w_1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.feed_forward.w_1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.feed_forward.w_2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.feed_forward.w_2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.norm1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.norm1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.norm2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.norm2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.norm3.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.1.norm3.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.self_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.src_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.feed_forward.w_1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.feed_forward.w_1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.feed_forward.w_2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.feed_forward.w_2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.norm1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.norm1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.norm2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.norm2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.norm3.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.2.norm3.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.self_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.src_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.feed_forward.w_1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.feed_forward.w_1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.feed_forward.w_2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.feed_forward.w_2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.norm1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.norm1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.norm2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.norm2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.norm3.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.3.norm3.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.self_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.src_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.feed_forward.w_1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.feed_forward.w_1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.feed_forward.w_2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.feed_forward.w_2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.norm1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.norm1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.norm2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.norm2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.norm3.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.4.norm3.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.self_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_q.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_q.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_k.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_k.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_v.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_v.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_out.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.src_attn.linear_out.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.feed_forward.w_1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.feed_forward.w_1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.feed_forward.w_2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.feed_forward.w_2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.norm1.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.norm1.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.norm2.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.norm2.bias. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.norm3.weight. It will not be updated during training.\n",
      "WARNING:root:Freezing decoder.decoders.5.norm3.bias. It will not be updated during training.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.set_device(args.rank)\n",
    "if not os.path.exists(args.outdir):\n",
    "    os.makedirs(args.outdir)\n",
    "    \n",
    "### Dataset Preparation ###\n",
    "dataset = {\n",
    "    \"train\": PretrainingMelDataset(feat_base_dir, dataset_dir, [scaler[input_type],scaler[\"mel\"]], \"train\", input_output_type=[input_type, \"mel\"], defiling_ratio=[0,0,1]),\n",
    "    \"dev\": PretrainingMelDataset(feat_base_dir, dataset_dir, [scaler[input_type],scaler[\"mel\"]], \"valid\", input_output_type=[input_type, \"mel\"], defiling_ratio=[0,0,1]),\n",
    "}\n",
    "\n",
    "collater_class = getattr(\n",
    "    seq2seq_vc.collaters,\n",
    "    config.get(\"collater_type\", \"ARM2MVCCollater\"),\n",
    ")\n",
    "collater = collater_class()\n",
    "\n",
    "sampler = {\"train\": None, \"dev\": None}\n",
    "data_loader = {\n",
    "    \"train\": DataLoader(\n",
    "        dataset=dataset[\"train\"],\n",
    "        shuffle=True,\n",
    "        collate_fn=collater,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        sampler=sampler[\"train\"],\n",
    "        pin_memory=config[\"pin_memory\"],\n",
    "    ),\n",
    "    \"dev\": DataLoader(\n",
    "        dataset=dataset[\"dev\"],\n",
    "        shuffle=True,\n",
    "        collate_fn=collater,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        num_workers=config[\"num_workers\"],\n",
    "        sampler=sampler[\"dev\"],\n",
    "        pin_memory=config[\"pin_memory\"],\n",
    "    ),\n",
    "}\n",
    "\n",
    "### Model Preparation ###\n",
    "model_class = getattr(\n",
    "    seq2seq_vc.models,\n",
    "    config.get(\"model_type\", \"M2MVTN\"),\n",
    ")\n",
    "model = model_class(**config[\"model_params\"]).to(device)\n",
    "\n",
    "if config.get(\"criterions\", None):\n",
    "    criterion = {\n",
    "        criterion_class: getattr(seq2seq_vc.losses, criterion_class)(\n",
    "            **criterion_paramaters\n",
    "        )\n",
    "        for criterion_class, criterion_paramaters in config[\"criterions\"].items()\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(\"Please specify criterions in the config file.\")\n",
    "\n",
    "### optimizers and schedulers ###\n",
    "optimizer_class = getattr(\n",
    "    torch.optim,\n",
    "    # keep compatibility\n",
    "    config.get(\"optimizer_type\", \"Adam\"),\n",
    ")\n",
    "optimizer = optimizer_class(\n",
    "    model.parameters(),\n",
    "    **config[\"optimizer_params\"],\n",
    ")\n",
    "scheduler_class = scheduler_classes.get(config.get(\"scheduler_type\", \"warmuplr\"))\n",
    "scheduler = scheduler_class(\n",
    "    optimizer=optimizer,\n",
    "    **config[\"scheduler_params\"],\n",
    ")\n",
    "\n",
    "### define trainer ###\n",
    "trainer_class = getattr(\n",
    "    seq2seq_vc.trainers,\n",
    "    config.get(\"trainer_type\", \"ARM2MVCTrainer\"),\n",
    ")\n",
    "trainer = trainer_class(\n",
    "    steps=0,\n",
    "    epochs=0,\n",
    "    data_loader=data_loader,\n",
    "    sampler=sampler,\n",
    "    model=model,\n",
    "    vocoder=None,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    config=config,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# load pretrained parameters from checkpoint\n",
    "if len(args.init_checkpoint) != 0:\n",
    "    trainer.load_trained_modules(\n",
    "        args.init_checkpoint, init_mods=config[\"init-mods\"]\n",
    "    )\n",
    "\n",
    "# resume from checkpoint\n",
    "if len(args.resume) != 0:\n",
    "    trainer.load_checkpoint(args.resume)\n",
    "\n",
    "# freeze modules if necessary\n",
    "if config.get(\"freeze-mods\", None) is not None:\n",
    "    assert type(config[\"freeze-mods\"]) is list\n",
    "    trainer.freeze_modules(config[\"freeze-mods\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0140f00-ef41-4322-9089-1ddd10bd9d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdc6c57-cf10-42d2-a759-b9f28a9a1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train]:   0%|          | 10/500000 [00:06<48:50:39,  2.84it/s]\n",
      "[eval]:   0%|          | 0/90 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "[eval]:   1%|          | 1/90 [00:00<01:01,  1.46it/s]\u001b[A\n",
      "[eval]:   2%|▏         | 2/90 [00:01<00:44,  1.99it/s]\u001b[A\n",
      "[eval]:   3%|▎         | 3/90 [00:01<00:29,  2.91it/s]\u001b[A\n",
      "[eval]:   4%|▍         | 4/90 [00:01<00:24,  3.50it/s]\u001b[A\n",
      "[eval]:   6%|▌         | 5/90 [00:01<00:20,  4.21it/s]\u001b[A\n",
      "[eval]:   7%|▋         | 6/90 [00:01<00:17,  4.73it/s]\u001b[A\n",
      "[eval]:   8%|▊         | 7/90 [00:02<00:18,  4.38it/s]\u001b[A\n",
      "[eval]:   9%|▉         | 8/90 [00:02<00:16,  4.90it/s]\u001b[A\n",
      "[eval]:  10%|█         | 9/90 [00:02<00:18,  4.41it/s]\u001b[A\n",
      "[eval]:  11%|█         | 10/90 [00:02<00:15,  5.11it/s]\u001b[A\n",
      "[eval]:  12%|█▏        | 11/90 [00:02<00:18,  4.39it/s]\u001b[A\n",
      "[eval]:  13%|█▎        | 12/90 [00:03<00:16,  4.87it/s]\u001b[A\n",
      "[eval]:  14%|█▍        | 13/90 [00:03<00:16,  4.55it/s]\u001b[A\n",
      "[eval]:  16%|█▌        | 14/90 [00:03<00:15,  4.86it/s]\u001b[A\n",
      "[eval]:  17%|█▋        | 15/90 [00:03<00:15,  4.94it/s]\u001b[A\n",
      "[eval]:  18%|█▊        | 16/90 [00:03<00:15,  4.91it/s]\u001b[A\n",
      "[eval]:  19%|█▉        | 17/90 [00:04<00:14,  4.88it/s]\u001b[A\n",
      "[eval]:  20%|██        | 18/90 [00:04<00:13,  5.50it/s]\u001b[A\n",
      "[eval]:  21%|██        | 19/90 [00:04<00:14,  4.96it/s]\u001b[A\n",
      "[eval]:  22%|██▏       | 20/90 [00:04<00:12,  5.50it/s]\u001b[A\n",
      "[eval]:  23%|██▎       | 21/90 [00:04<00:14,  4.93it/s]\u001b[A\n",
      "[eval]:  24%|██▍       | 22/90 [00:04<00:13,  5.16it/s]\u001b[A\n",
      "[eval]:  26%|██▌       | 23/90 [00:05<00:14,  4.65it/s]\u001b[A\n",
      "[eval]:  27%|██▋       | 24/90 [00:05<00:13,  5.04it/s]\u001b[A\n",
      "[eval]:  28%|██▊       | 25/90 [00:05<00:14,  4.61it/s]\u001b[A\n",
      "[eval]:  29%|██▉       | 26/90 [00:05<00:12,  5.00it/s]\u001b[A\n",
      "[eval]:  30%|███       | 27/90 [00:06<00:13,  4.50it/s]\u001b[A\n",
      "[eval]:  31%|███       | 28/90 [00:06<00:13,  4.76it/s]\u001b[A\n",
      "[eval]:  32%|███▏      | 29/90 [00:06<00:13,  4.39it/s]\u001b[A\n",
      "[eval]:  33%|███▎      | 30/90 [00:06<00:12,  4.91it/s]\u001b[A\n",
      "[eval]:  34%|███▍      | 31/90 [00:06<00:13,  4.53it/s]\u001b[A\n",
      "[eval]:  36%|███▌      | 32/90 [00:07<00:11,  5.00it/s]\u001b[A\n",
      "[eval]:  37%|███▋      | 33/90 [00:07<00:12,  4.53it/s]\u001b[A\n",
      "[eval]:  38%|███▊      | 34/90 [00:07<00:11,  4.94it/s]\u001b[A\n",
      "[eval]:  39%|███▉      | 35/90 [00:07<00:12,  4.55it/s]\u001b[A\n",
      "[eval]:  40%|████      | 36/90 [00:07<00:10,  5.01it/s]\u001b[A\n",
      "[eval]:  41%|████      | 37/90 [00:08<00:11,  4.67it/s]\u001b[A\n",
      "[eval]:  42%|████▏     | 38/90 [00:08<00:10,  5.20it/s]\u001b[A\n",
      "[eval]:  43%|████▎     | 39/90 [00:08<00:10,  4.82it/s]\u001b[A\n",
      "[eval]:  44%|████▍     | 40/90 [00:08<00:09,  5.16it/s]\u001b[A\n",
      "[eval]:  46%|████▌     | 41/90 [00:08<00:10,  4.82it/s]\u001b[A\n",
      "[eval]:  47%|████▋     | 42/90 [00:09<00:08,  5.37it/s]\u001b[A\n",
      "[eval]:  48%|████▊     | 43/90 [00:09<00:09,  4.87it/s]\u001b[A\n",
      "[eval]:  49%|████▉     | 44/90 [00:09<00:08,  5.37it/s]\u001b[A\n",
      "[eval]:  50%|█████     | 45/90 [00:09<00:09,  4.90it/s]\u001b[A\n",
      "[eval]:  51%|█████     | 46/90 [00:09<00:08,  5.33it/s]\u001b[A\n",
      "[eval]:  52%|█████▏    | 47/90 [00:10<00:09,  4.74it/s]\u001b[A\n",
      "[eval]:  53%|█████▎    | 48/90 [00:10<00:08,  5.18it/s]\u001b[A\n",
      "[eval]:  54%|█████▍    | 49/90 [00:10<00:09,  4.48it/s]\u001b[A\n",
      "[eval]:  56%|█████▌    | 50/90 [00:10<00:08,  4.70it/s]\u001b[A\n",
      "[eval]:  57%|█████▋    | 51/90 [00:11<00:08,  4.61it/s]\u001b[A\n",
      "[eval]:  58%|█████▊    | 52/90 [00:11<00:07,  5.19it/s]\u001b[A\n",
      "[eval]:  59%|█████▉    | 53/90 [00:11<00:08,  4.57it/s]\u001b[A\n",
      "[eval]:  60%|██████    | 54/90 [00:11<00:07,  4.76it/s]\u001b[A\n",
      "[eval]:  61%|██████    | 55/90 [00:11<00:07,  4.59it/s]\u001b[A\n",
      "[eval]:  62%|██████▏   | 56/90 [00:12<00:07,  4.72it/s]\u001b[A\n",
      "[eval]:  63%|██████▎   | 57/90 [00:12<00:07,  4.68it/s]\u001b[A\n",
      "[eval]:  64%|██████▍   | 58/90 [00:12<00:06,  5.02it/s]\u001b[A\n",
      "[eval]:  66%|██████▌   | 59/90 [00:12<00:06,  4.58it/s]\u001b[A\n",
      "[eval]:  67%|██████▋   | 60/90 [00:12<00:06,  4.91it/s]\u001b[A\n",
      "[eval]:  68%|██████▊   | 61/90 [00:13<00:06,  4.77it/s]\u001b[A\n",
      "[eval]:  69%|██████▉   | 62/90 [00:13<00:05,  4.88it/s]\u001b[A\n",
      "[eval]:  70%|███████   | 63/90 [00:13<00:05,  5.08it/s]\u001b[A\n",
      "[eval]:  71%|███████   | 64/90 [00:13<00:04,  5.30it/s]\u001b[A\n",
      "[eval]:  72%|███████▏  | 65/90 [00:13<00:05,  4.96it/s]\u001b[A\n",
      "[eval]:  73%|███████▎  | 66/90 [00:14<00:04,  5.14it/s]\u001b[A\n",
      "[eval]:  74%|███████▍  | 67/90 [00:14<00:04,  4.73it/s]\u001b[A\n",
      "[eval]:  76%|███████▌  | 68/90 [00:14<00:04,  5.08it/s]\u001b[A\n",
      "[eval]:  77%|███████▋  | 69/90 [00:14<00:04,  4.62it/s]\u001b[A\n",
      "[eval]:  78%|███████▊  | 70/90 [00:14<00:03,  5.11it/s]\u001b[A\n",
      "[eval]:  79%|███████▉  | 71/90 [00:15<00:04,  4.42it/s]\u001b[A\n",
      "[eval]:  80%|████████  | 72/90 [00:15<00:03,  4.84it/s]\u001b[A\n",
      "[eval]:  81%|████████  | 73/90 [00:15<00:03,  4.60it/s]\u001b[A\n",
      "[eval]:  82%|████████▏ | 74/90 [00:15<00:03,  4.86it/s]\u001b[A\n",
      "[eval]:  83%|████████▎ | 75/90 [00:16<00:03,  4.38it/s]\u001b[A\n",
      "[eval]:  84%|████████▍ | 76/90 [00:16<00:02,  4.81it/s]\u001b[A\n",
      "[eval]:  86%|████████▌ | 77/90 [00:16<00:02,  4.36it/s]\u001b[A\n",
      "[eval]:  87%|████████▋ | 78/90 [00:16<00:02,  4.72it/s]\u001b[A\n",
      "[eval]:  88%|████████▊ | 79/90 [00:16<00:02,  4.64it/s]\u001b[A\n",
      "[eval]:  89%|████████▉ | 80/90 [00:17<00:02,  5.00it/s]\u001b[A\n",
      "[eval]:  90%|█████████ | 81/90 [00:17<00:01,  4.83it/s]\u001b[A\n",
      "[eval]:  91%|█████████ | 82/90 [00:17<00:01,  5.13it/s]\u001b[A\n",
      "[eval]:  92%|█████████▏| 83/90 [00:17<00:01,  4.88it/s]\u001b[A\n",
      "[eval]:  93%|█████████▎| 84/90 [00:17<00:01,  5.28it/s]\u001b[A\n",
      "[eval]:  94%|█████████▍| 85/90 [00:18<00:01,  4.74it/s]\u001b[A\n",
      "[eval]:  96%|█████████▌| 86/90 [00:18<00:00,  5.31it/s]\u001b[A\n",
      "[eval]:  97%|█████████▋| 87/90 [00:18<00:00,  4.99it/s]\u001b[A\n",
      "[eval]:  98%|█████████▊| 88/90 [00:18<00:00,  5.35it/s]\u001b[A\n",
      "[eval]:  99%|█████████▉| 89/90 [00:18<00:00,  5.54it/s]\u001b[A\n",
      "[eval]: 100%|██████████| 90/90 [00:19<00:00,  4.70it/s]\u001b[A\n",
      "[train]:   0%|          | 20/500000 [00:28<77:26:54,  1.79it/s] \n",
      "[eval]:   0%|          | 0/90 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "[eval]:   1%|          | 1/90 [00:00<00:52,  1.70it/s]\u001b[A\n",
      "[eval]:   2%|▏         | 2/90 [00:00<00:34,  2.57it/s]\u001b[A\n",
      "[eval]:   3%|▎         | 3/90 [00:01<00:24,  3.53it/s]\u001b[A\n",
      "[eval]:   4%|▍         | 4/90 [00:01<00:20,  4.25it/s]\u001b[A\n",
      "[eval]:   6%|▌         | 5/90 [00:01<00:20,  4.19it/s]\u001b[A\n",
      "[eval]:   7%|▋         | 6/90 [00:01<00:17,  4.79it/s]\u001b[A\n",
      "[eval]:   8%|▊         | 7/90 [00:01<00:19,  4.27it/s]\u001b[A\n",
      "[eval]:   9%|▉         | 8/90 [00:02<00:16,  4.86it/s]\u001b[A\n",
      "[eval]:  10%|█         | 9/90 [00:02<00:19,  4.09it/s]\u001b[A\n",
      "[eval]:  11%|█         | 10/90 [00:02<00:17,  4.68it/s]\u001b[A\n",
      "[eval]:  12%|█▏        | 11/90 [00:02<00:17,  4.50it/s]\u001b[A\n",
      "[eval]:  13%|█▎        | 12/90 [00:02<00:16,  4.76it/s]\u001b[A\n",
      "[eval]:  14%|█▍        | 13/90 [00:03<00:17,  4.35it/s]\u001b[A\n",
      "[eval]:  16%|█▌        | 14/90 [00:03<00:15,  4.80it/s]\u001b[A\n",
      "[eval]:  17%|█▋        | 15/90 [00:03<00:17,  4.33it/s]\u001b[A\n",
      "[eval]:  18%|█▊        | 16/90 [00:03<00:15,  4.80it/s]\u001b[A\n",
      "[eval]:  19%|█▉        | 17/90 [00:04<00:16,  4.32it/s]\u001b[A\n",
      "[eval]:  20%|██        | 18/90 [00:04<00:14,  4.88it/s]\u001b[A\n",
      "[eval]:  21%|██        | 19/90 [00:04<00:14,  4.73it/s]\u001b[A\n",
      "[eval]:  22%|██▏       | 20/90 [00:04<00:13,  5.13it/s]\u001b[A\n",
      "[eval]:  23%|██▎       | 21/90 [00:04<00:14,  4.80it/s]\u001b[A\n",
      "[eval]:  24%|██▍       | 22/90 [00:04<00:13,  5.20it/s]\u001b[A\n",
      "[eval]:  26%|██▌       | 23/90 [00:05<00:13,  4.87it/s]\u001b[A\n",
      "[eval]:  27%|██▋       | 24/90 [00:05<00:13,  4.95it/s]\u001b[A\n",
      "[eval]:  28%|██▊       | 25/90 [00:05<00:13,  4.82it/s]\u001b[A\n",
      "[eval]:  29%|██▉       | 26/90 [00:05<00:12,  5.05it/s]\u001b[A\n",
      "[eval]:  30%|███       | 27/90 [00:06<00:13,  4.83it/s]\u001b[A\n",
      "[eval]:  31%|███       | 28/90 [00:06<00:12,  5.04it/s]\u001b[A\n",
      "[eval]:  32%|███▏      | 29/90 [00:06<00:12,  4.80it/s]\u001b[A\n",
      "[eval]:  33%|███▎      | 30/90 [00:06<00:11,  5.08it/s]\u001b[A\n",
      "[eval]:  34%|███▍      | 31/90 [00:06<00:11,  4.99it/s]\u001b[A\n",
      "[eval]:  36%|███▌      | 32/90 [00:07<00:11,  5.17it/s]\u001b[A\n",
      "[eval]:  37%|███▋      | 33/90 [00:07<00:12,  4.58it/s]\u001b[A\n",
      "[eval]:  38%|███▊      | 34/90 [00:07<00:11,  4.68it/s]\u001b[A\n",
      "[eval]:  39%|███▉      | 35/90 [00:07<00:11,  4.67it/s]\u001b[A\n",
      "[eval]:  40%|████      | 36/90 [00:07<00:11,  4.88it/s]\u001b[A\n",
      "[eval]:  41%|████      | 37/90 [00:08<00:11,  4.55it/s]\u001b[A\n",
      "[eval]:  42%|████▏     | 38/90 [00:08<00:10,  4.89it/s]\u001b[A\n",
      "[eval]:  43%|████▎     | 39/90 [00:08<00:11,  4.49it/s]\u001b[A\n",
      "[eval]:  44%|████▍     | 40/90 [00:08<00:10,  4.78it/s]\u001b[A\n",
      "[eval]:  46%|████▌     | 41/90 [00:08<00:10,  4.46it/s]\u001b[A\n",
      "[eval]:  47%|████▋     | 42/90 [00:09<00:10,  4.73it/s]\u001b[A\n",
      "[eval]:  48%|████▊     | 43/90 [00:09<00:10,  4.69it/s]\u001b[A\n",
      "[eval]:  49%|████▉     | 44/90 [00:09<00:09,  4.90it/s]\u001b[A\n",
      "[eval]:  50%|█████     | 45/90 [00:09<00:09,  4.80it/s]\u001b[A\n",
      "[eval]:  51%|█████     | 46/90 [00:09<00:08,  4.98it/s]\u001b[A\n",
      "[eval]:  52%|█████▏    | 47/90 [00:10<00:09,  4.65it/s]\u001b[A\n",
      "[eval]:  53%|█████▎    | 48/90 [00:10<00:08,  5.07it/s]\u001b[A\n",
      "[eval]:  54%|█████▍    | 49/90 [00:10<00:08,  5.08it/s]\u001b[A\n",
      "[eval]:  56%|█████▌    | 50/90 [00:10<00:07,  5.27it/s]\u001b[A\n",
      "[eval]:  57%|█████▋    | 51/90 [00:10<00:07,  4.94it/s]\u001b[A\n",
      "[eval]:  58%|█████▊    | 52/90 [00:11<00:07,  5.10it/s]\u001b[A\n",
      "[eval]:  59%|█████▉    | 53/90 [00:11<00:07,  4.78it/s]\u001b[A\n",
      "[eval]:  60%|██████    | 54/90 [00:11<00:07,  5.05it/s]\u001b[A\n",
      "[eval]:  61%|██████    | 55/90 [00:11<00:07,  4.61it/s]\u001b[A\n",
      "[eval]:  62%|██████▏   | 56/90 [00:12<00:07,  4.84it/s]\u001b[A\n",
      "[eval]:  63%|██████▎   | 57/90 [00:12<00:07,  4.56it/s]\u001b[A\n",
      "[eval]:  64%|██████▍   | 58/90 [00:12<00:06,  4.68it/s]\u001b[A\n",
      "[eval]:  66%|██████▌   | 59/90 [00:12<00:07,  4.41it/s]\u001b[A\n",
      "[eval]:  67%|██████▋   | 60/90 [00:12<00:06,  4.65it/s]\u001b[A\n",
      "[eval]:  68%|██████▊   | 61/90 [00:13<00:06,  4.29it/s]\u001b[A\n",
      "[eval]:  69%|██████▉   | 62/90 [00:13<00:05,  4.91it/s]\u001b[A\n",
      "[eval]:  70%|███████   | 63/90 [00:13<00:05,  4.59it/s]\u001b[A\n",
      "[eval]:  71%|███████   | 64/90 [00:13<00:05,  4.88it/s]\u001b[A\n",
      "[eval]:  72%|███████▏  | 65/90 [00:14<00:05,  4.41it/s]\u001b[A\n",
      "[eval]:  73%|███████▎  | 66/90 [00:14<00:05,  4.80it/s]\u001b[A\n",
      "[eval]:  74%|███████▍  | 67/90 [00:14<00:04,  4.73it/s]\u001b[A\n",
      "[eval]:  76%|███████▌  | 68/90 [00:14<00:04,  5.07it/s]\u001b[A\n",
      "[eval]:  77%|███████▋  | 69/90 [00:14<00:04,  4.78it/s]\u001b[A\n",
      "[eval]:  78%|███████▊  | 70/90 [00:14<00:03,  5.16it/s]\u001b[A\n",
      "[eval]:  79%|███████▉  | 71/90 [00:15<00:03,  5.04it/s]\u001b[A\n",
      "[eval]:  80%|████████  | 72/90 [00:15<00:03,  5.05it/s]\u001b[A\n",
      "[eval]:  81%|████████  | 73/90 [00:15<00:03,  4.84it/s]\u001b[A\n",
      "[eval]:  82%|████████▏ | 74/90 [00:15<00:03,  5.13it/s]\u001b[A\n",
      "[eval]:  83%|████████▎ | 75/90 [00:16<00:03,  4.85it/s]\u001b[A\n",
      "[eval]:  84%|████████▍ | 76/90 [00:16<00:02,  5.14it/s]\u001b[A\n",
      "[eval]:  86%|████████▌ | 77/90 [00:16<00:02,  4.79it/s]\u001b[A\n",
      "[eval]:  87%|████████▋ | 78/90 [00:16<00:02,  5.26it/s]\u001b[A\n",
      "[eval]:  88%|████████▊ | 79/90 [00:16<00:02,  4.88it/s]\u001b[A\n",
      "[eval]:  89%|████████▉ | 80/90 [00:16<00:01,  5.27it/s]\u001b[A\n",
      "[eval]:  90%|█████████ | 81/90 [00:17<00:01,  5.21it/s]\u001b[A\n",
      "[eval]:  91%|█████████ | 82/90 [00:17<00:01,  5.26it/s]\u001b[A\n",
      "[eval]:  92%|█████████▏| 83/90 [00:17<00:01,  5.00it/s]\u001b[A\n",
      "[eval]:  93%|█████████▎| 84/90 [00:17<00:01,  4.99it/s]\u001b[A\n",
      "[eval]:  94%|█████████▍| 85/90 [00:17<00:01,  4.72it/s]\u001b[A\n",
      "[eval]:  96%|█████████▌| 86/90 [00:18<00:00,  5.16it/s]\u001b[A\n",
      "[eval]:  97%|█████████▋| 87/90 [00:18<00:00,  4.55it/s]\u001b[A\n",
      "[eval]:  98%|█████████▊| 88/90 [00:18<00:00,  5.00it/s]\u001b[A\n",
      "[eval]: 100%|██████████| 90/90 [00:18<00:00,  4.76it/s]\u001b[A\n",
      "[train]:   0%|          | 30/500000 [00:50<76:51:06,  1.81it/s] \n",
      "[eval]:   0%|          | 0/90 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "[eval]:   1%|          | 1/90 [00:00<00:52,  1.71it/s]\u001b[A\n",
      "[eval]:   2%|▏         | 2/90 [00:00<00:30,  2.90it/s]\u001b[A\n",
      "[eval]:   3%|▎         | 3/90 [00:00<00:23,  3.67it/s]\u001b[A\n",
      "[eval]:   4%|▍         | 4/90 [00:01<00:19,  4.34it/s]\u001b[A\n",
      "[eval]:   6%|▌         | 5/90 [00:01<00:21,  3.95it/s]\u001b[A\n",
      "[eval]:   7%|▋         | 6/90 [00:01<00:19,  4.39it/s]\u001b[A\n",
      "[eval]:   8%|▊         | 7/90 [00:01<00:20,  4.04it/s]\u001b[A\n",
      "[eval]:   9%|▉         | 8/90 [00:02<00:18,  4.52it/s]\u001b[A\n",
      "[eval]:  10%|█         | 9/90 [00:02<00:18,  4.29it/s]\u001b[A\n",
      "[eval]:  11%|█         | 10/90 [00:02<00:16,  4.77it/s]\u001b[A\n",
      "[eval]:  12%|█▏        | 11/90 [00:02<00:19,  4.08it/s]\u001b[A\n",
      "[eval]:  13%|█▎        | 12/90 [00:02<00:17,  4.51it/s]\u001b[A\n",
      "[eval]:  14%|█▍        | 13/90 [00:03<00:17,  4.42it/s]\u001b[A\n",
      "[eval]:  16%|█▌        | 14/90 [00:03<00:15,  5.03it/s]\u001b[A\n",
      "[eval]:  17%|█▋        | 15/90 [00:03<00:15,  4.81it/s]\u001b[A\n",
      "[eval]:  18%|█▊        | 16/90 [00:03<00:14,  5.09it/s]\u001b[A\n",
      "[eval]:  19%|█▉        | 17/90 [00:03<00:15,  4.75it/s]\u001b[A\n",
      "[eval]:  20%|██        | 18/90 [00:04<00:13,  5.26it/s]\u001b[A\n",
      "[eval]:  21%|██        | 19/90 [00:04<00:14,  4.84it/s]\u001b[A\n",
      "[eval]:  22%|██▏       | 20/90 [00:04<00:13,  5.24it/s]\u001b[A\n",
      "[eval]:  23%|██▎       | 21/90 [00:04<00:13,  4.93it/s]\u001b[A\n",
      "[eval]:  24%|██▍       | 22/90 [00:04<00:12,  5.39it/s]\u001b[A\n",
      "[eval]:  26%|██▌       | 23/90 [00:05<00:14,  4.67it/s]\u001b[A\n",
      "[eval]:  27%|██▋       | 24/90 [00:05<00:12,  5.09it/s]\u001b[A\n",
      "[eval]:  28%|██▊       | 25/90 [00:05<00:12,  5.15it/s]\u001b[A\n",
      "[eval]:  29%|██▉       | 26/90 [00:05<00:11,  5.43it/s]\u001b[A\n",
      "[eval]:  30%|███       | 27/90 [00:05<00:12,  5.13it/s]\u001b[A\n",
      "[eval]:  31%|███       | 28/90 [00:06<00:11,  5.45it/s]\u001b[A\n",
      "[eval]:  32%|███▏      | 29/90 [00:06<00:12,  5.07it/s]\u001b[A\n",
      "[eval]:  33%|███▎      | 30/90 [00:06<00:11,  5.32it/s]\u001b[A\n",
      "[eval]:  34%|███▍      | 31/90 [00:06<00:11,  4.97it/s]\u001b[A\n",
      "[eval]:  36%|███▌      | 32/90 [00:06<00:10,  5.44it/s]\u001b[A\n",
      "[eval]:  37%|███▋      | 33/90 [00:07<00:11,  4.80it/s]\u001b[A\n",
      "[eval]:  38%|███▊      | 34/90 [00:07<00:11,  4.91it/s]\u001b[A\n",
      "[eval]:  39%|███▉      | 35/90 [00:07<00:11,  4.80it/s]\u001b[A\n",
      "[eval]:  40%|████      | 36/90 [00:07<00:10,  5.12it/s]\u001b[A\n",
      "[eval]:  41%|████      | 37/90 [00:07<00:11,  4.59it/s]\u001b[A\n",
      "[eval]:  42%|████▏     | 38/90 [00:08<00:10,  4.85it/s]\u001b[A\n",
      "[eval]:  43%|████▎     | 39/90 [00:08<00:10,  4.78it/s]\u001b[A\n",
      "[eval]:  44%|████▍     | 40/90 [00:08<00:09,  5.12it/s]\u001b[A\n",
      "[eval]:  46%|████▌     | 41/90 [00:08<00:10,  4.62it/s]\u001b[A\n",
      "[eval]:  47%|████▋     | 42/90 [00:08<00:09,  4.89it/s]\u001b[A\n",
      "[eval]:  48%|████▊     | 43/90 [00:09<00:10,  4.55it/s]\u001b[A\n",
      "[eval]:  49%|████▉     | 44/90 [00:09<00:09,  4.82it/s]\u001b[A\n",
      "[eval]:  50%|█████     | 45/90 [00:09<00:09,  4.57it/s]\u001b[A\n",
      "[eval]:  51%|█████     | 46/90 [00:09<00:08,  5.00it/s]\u001b[A\n",
      "[eval]:  52%|█████▏    | 47/90 [00:10<00:09,  4.66it/s]\u001b[A\n",
      "[eval]:  53%|█████▎    | 48/90 [00:10<00:08,  5.02it/s]\u001b[A\n",
      "[eval]:  54%|█████▍    | 49/90 [00:10<00:08,  4.96it/s]\u001b[A\n",
      "[eval]:  56%|█████▌    | 50/90 [00:10<00:07,  5.21it/s]\u001b[A\n",
      "[eval]:  57%|█████▋    | 51/90 [00:10<00:07,  4.92it/s]\u001b[A\n",
      "[eval]:  58%|█████▊    | 52/90 [00:10<00:07,  5.32it/s]\u001b[A\n",
      "[eval]:  59%|█████▉    | 53/90 [00:11<00:08,  4.57it/s]\u001b[A\n",
      "[eval]:  60%|██████    | 54/90 [00:11<00:07,  5.05it/s]\u001b[A\n",
      "[eval]:  61%|██████    | 55/90 [00:11<00:07,  4.68it/s]\u001b[A\n",
      "[eval]:  62%|██████▏   | 56/90 [00:11<00:06,  5.07it/s]\u001b[A\n",
      "[eval]:  63%|██████▎   | 57/90 [00:12<00:07,  4.29it/s]\u001b[A\n",
      "[eval]:  64%|██████▍   | 58/90 [00:12<00:06,  4.72it/s]\u001b[A\n",
      "[eval]:  66%|██████▌   | 59/90 [00:12<00:07,  4.41it/s]\u001b[A\n",
      "[eval]:  67%|██████▋   | 60/90 [00:12<00:06,  4.68it/s]\u001b[A\n",
      "[eval]:  68%|██████▊   | 61/90 [00:12<00:06,  4.58it/s]\u001b[A\n",
      "[eval]:  69%|██████▉   | 62/90 [00:13<00:05,  4.85it/s]\u001b[A\n",
      "[eval]:  70%|███████   | 63/90 [00:13<00:06,  4.43it/s]\u001b[A\n",
      "[eval]:  71%|███████   | 64/90 [00:13<00:05,  4.84it/s]\u001b[A\n",
      "[eval]:  72%|███████▏  | 65/90 [00:13<00:05,  4.45it/s]\u001b[A\n",
      "[eval]:  73%|███████▎  | 66/90 [00:14<00:05,  4.73it/s]\u001b[A\n",
      "[eval]:  74%|███████▍  | 67/90 [00:14<00:05,  4.48it/s]\u001b[A\n",
      "[eval]:  76%|███████▌  | 68/90 [00:14<00:04,  4.84it/s]\u001b[A\n",
      "[eval]:  77%|███████▋  | 69/90 [00:14<00:04,  4.76it/s]\u001b[A\n",
      "[eval]:  78%|███████▊  | 70/90 [00:14<00:03,  5.08it/s]\u001b[A\n",
      "[eval]:  79%|███████▉  | 71/90 [00:15<00:03,  4.84it/s]\u001b[A\n",
      "[eval]:  80%|████████  | 72/90 [00:15<00:03,  5.19it/s]\u001b[A\n",
      "[eval]:  81%|████████  | 73/90 [00:15<00:03,  5.07it/s]\u001b[A\n",
      "[eval]:  82%|████████▏ | 74/90 [00:15<00:02,  5.37it/s]\u001b[A\n",
      "[eval]:  83%|████████▎ | 75/90 [00:15<00:03,  4.93it/s]\u001b[A\n",
      "[eval]:  84%|████████▍ | 76/90 [00:15<00:02,  5.23it/s]\u001b[A\n",
      "[eval]:  86%|████████▌ | 77/90 [00:16<00:02,  4.86it/s]\u001b[A\n",
      "[eval]:  87%|████████▋ | 78/90 [00:16<00:02,  5.28it/s]\u001b[A\n",
      "[eval]:  88%|████████▊ | 79/90 [00:16<00:02,  5.01it/s]\u001b[A\n",
      "[eval]:  89%|████████▉ | 80/90 [00:16<00:01,  5.44it/s]\u001b[A\n",
      "[eval]:  90%|█████████ | 81/90 [00:16<00:01,  4.82it/s]\u001b[A\n",
      "[eval]:  91%|█████████ | 82/90 [00:17<00:01,  5.22it/s]\u001b[A\n",
      "[eval]:  92%|█████████▏| 83/90 [00:17<00:01,  4.75it/s]\u001b[A\n",
      "[eval]:  93%|█████████▎| 84/90 [00:17<00:01,  5.22it/s]\u001b[A\n",
      "[eval]:  94%|█████████▍| 85/90 [00:17<00:01,  4.64it/s]\u001b[A\n",
      "[eval]:  96%|█████████▌| 86/90 [00:17<00:00,  5.06it/s]\u001b[A\n",
      "[eval]:  97%|█████████▋| 87/90 [00:18<00:00,  4.86it/s]\u001b[A\n",
      "[eval]:  98%|█████████▊| 88/90 [00:18<00:00,  5.07it/s]\u001b[A\n",
      "[eval]: 100%|██████████| 90/90 [00:18<00:00,  4.81it/s]\u001b[A\n",
      "[train]:   0%|          | 40/500000 [01:12<78:58:59,  1.76it/s] \n",
      "[eval]:   0%|          | 0/90 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "[eval]:   1%|          | 1/90 [00:00<00:53,  1.67it/s]\u001b[A\n",
      "[eval]:   2%|▏         | 2/90 [00:00<00:29,  2.95it/s]\u001b[A\n",
      "[eval]:   3%|▎         | 3/90 [00:00<00:23,  3.65it/s]\u001b[A\n",
      "[eval]:   4%|▍         | 4/90 [00:01<00:19,  4.37it/s]\u001b[A\n",
      "[eval]:   6%|▌         | 5/90 [00:01<00:20,  4.24it/s]\u001b[A\n",
      "[eval]:   7%|▋         | 6/90 [00:01<00:17,  4.78it/s]\u001b[A\n",
      "[eval]:   8%|▊         | 7/90 [00:01<00:17,  4.66it/s]\u001b[A\n",
      "[eval]:   9%|▉         | 8/90 [00:01<00:16,  4.98it/s]\u001b[A\n",
      "[eval]:  10%|█         | 9/90 [00:02<00:17,  4.73it/s]\u001b[A\n",
      "[eval]:  11%|█         | 10/90 [00:02<00:15,  5.32it/s]\u001b[A\n",
      "[eval]:  12%|█▏        | 11/90 [00:02<00:16,  4.65it/s]\u001b[A\n",
      "[eval]:  13%|█▎        | 12/90 [00:02<00:15,  5.03it/s]\u001b[A\n",
      "[eval]:  14%|█▍        | 13/90 [00:02<00:16,  4.63it/s]\u001b[A\n",
      "[eval]:  16%|█▌        | 14/90 [00:03<00:15,  4.93it/s]\u001b[A\n",
      "[eval]:  17%|█▋        | 15/90 [00:03<00:16,  4.53it/s]\u001b[A\n",
      "[eval]:  18%|█▊        | 16/90 [00:03<00:15,  4.93it/s]\u001b[A\n",
      "[eval]:  19%|█▉        | 17/90 [00:03<00:16,  4.49it/s]\u001b[A\n",
      "[eval]:  20%|██        | 18/90 [00:04<00:14,  4.99it/s]\u001b[A\n",
      "[eval]:  21%|██        | 19/90 [00:04<00:15,  4.52it/s]\u001b[A\n",
      "[eval]:  22%|██▏       | 20/90 [00:04<00:14,  4.93it/s]\u001b[A\n",
      "[eval]:  23%|██▎       | 21/90 [00:04<00:15,  4.55it/s]\u001b[A\n",
      "[eval]:  24%|██▍       | 22/90 [00:04<00:14,  4.84it/s]\u001b[A\n",
      "[eval]:  26%|██▌       | 23/90 [00:05<00:15,  4.34it/s]\u001b[A\n",
      "[eval]:  27%|██▋       | 24/90 [00:05<00:13,  4.76it/s]\u001b[A\n",
      "[eval]:  28%|██▊       | 25/90 [00:05<00:15,  4.29it/s]\u001b[A\n",
      "[eval]:  29%|██▉       | 26/90 [00:05<00:13,  4.85it/s]\u001b[A\n",
      "[eval]:  30%|███       | 27/90 [00:05<00:13,  4.61it/s]\u001b[A\n",
      "[eval]:  31%|███       | 28/90 [00:06<00:12,  4.91it/s]\u001b[A\n",
      "[eval]:  32%|███▏      | 29/90 [00:06<00:12,  4.93it/s]\u001b[A\n",
      "[eval]:  33%|███▎      | 30/90 [00:06<00:11,  5.08it/s]\u001b[A\n",
      "[eval]:  34%|███▍      | 31/90 [00:06<00:12,  4.69it/s]\u001b[A\n",
      "[eval]:  36%|███▌      | 32/90 [00:06<00:11,  5.13it/s]\u001b[A\n",
      "[eval]:  37%|███▋      | 33/90 [00:07<00:11,  5.09it/s]\u001b[A\n",
      "[eval]:  38%|███▊      | 34/90 [00:07<00:10,  5.47it/s]\u001b[A\n",
      "[eval]:  39%|███▉      | 35/90 [00:07<00:11,  4.82it/s]\u001b[A\n",
      "[eval]:  40%|████      | 36/90 [00:07<00:10,  5.16it/s]\u001b[A\n",
      "[eval]:  41%|████      | 37/90 [00:08<00:11,  4.46it/s]\u001b[A\n",
      "[eval]:  42%|████▏     | 38/90 [00:08<00:10,  4.87it/s]\u001b[A\n",
      "[eval]:  43%|████▎     | 39/90 [00:08<00:11,  4.56it/s]\u001b[A\n",
      "[eval]:  44%|████▍     | 40/90 [00:08<00:10,  4.93it/s]\u001b[A\n",
      "[eval]:  46%|████▌     | 41/90 [00:08<00:11,  4.41it/s]\u001b[A\n",
      "[eval]:  47%|████▋     | 42/90 [00:09<00:09,  4.83it/s]\u001b[A\n",
      "[eval]:  48%|████▊     | 43/90 [00:09<00:10,  4.31it/s]\u001b[A\n",
      "[eval]:  49%|████▉     | 44/90 [00:09<00:09,  4.75it/s]\u001b[A\n",
      "[eval]:  50%|█████     | 45/90 [00:09<00:10,  4.48it/s]\u001b[A\n",
      "[eval]:  51%|█████     | 46/90 [00:09<00:09,  4.76it/s]\u001b[A\n",
      "[eval]:  52%|█████▏    | 47/90 [00:10<00:09,  4.54it/s]\u001b[A\n",
      "[eval]:  53%|█████▎    | 48/90 [00:10<00:08,  5.02it/s]\u001b[A\n",
      "[eval]:  54%|█████▍    | 49/90 [00:10<00:09,  4.52it/s]\u001b[A\n",
      "[eval]:  56%|█████▌    | 50/90 [00:10<00:08,  4.95it/s]\u001b[A\n",
      "[eval]:  57%|█████▋    | 51/90 [00:11<00:08,  4.64it/s]\u001b[A\n",
      "[eval]:  58%|█████▊    | 52/90 [00:11<00:07,  5.09it/s]\u001b[A\n",
      "[eval]:  59%|█████▉    | 53/90 [00:11<00:07,  4.71it/s]\u001b[A\n",
      "[eval]:  60%|██████    | 54/90 [00:11<00:07,  5.03it/s]\u001b[A\n",
      "[eval]:  61%|██████    | 55/90 [00:11<00:07,  4.86it/s]\u001b[A\n",
      "[eval]:  62%|██████▏   | 56/90 [00:11<00:06,  5.34it/s]\u001b[A\n",
      "[eval]:  63%|██████▎   | 57/90 [00:12<00:06,  4.93it/s]\u001b[A\n",
      "[eval]:  64%|██████▍   | 58/90 [00:12<00:05,  5.34it/s]\u001b[A\n",
      "[eval]:  66%|██████▌   | 59/90 [00:12<00:06,  4.66it/s]\u001b[A\n",
      "[eval]:  67%|██████▋   | 60/90 [00:12<00:05,  5.04it/s]\u001b[A\n",
      "[eval]:  68%|██████▊   | 61/90 [00:12<00:05,  5.04it/s]\u001b[A\n",
      "[eval]:  69%|██████▉   | 62/90 [00:13<00:05,  5.32it/s]\u001b[A\n",
      "[eval]:  70%|███████   | 63/90 [00:13<00:05,  5.08it/s]\u001b[A\n",
      "[eval]:  71%|███████   | 64/90 [00:13<00:04,  5.40it/s]\u001b[A\n",
      "[eval]:  72%|███████▏  | 65/90 [00:13<00:05,  4.99it/s]\u001b[A\n",
      "[eval]:  73%|███████▎  | 66/90 [00:13<00:04,  5.22it/s]\u001b[A\n",
      "[eval]:  74%|███████▍  | 67/90 [00:14<00:04,  4.85it/s]\u001b[A\n",
      "[eval]:  76%|███████▌  | 68/90 [00:14<00:04,  5.10it/s]\u001b[A\n",
      "[eval]:  77%|███████▋  | 69/90 [00:14<00:04,  5.07it/s]\u001b[A\n",
      "[eval]:  78%|███████▊  | 70/90 [00:14<00:03,  5.24it/s]\u001b[A\n",
      "[eval]:  79%|███████▉  | 71/90 [00:14<00:04,  4.70it/s]\u001b[A\n",
      "[eval]:  80%|████████  | 72/90 [00:15<00:03,  4.83it/s]\u001b[A\n",
      "[eval]:  81%|████████  | 73/90 [00:15<00:03,  4.40it/s]\u001b[A\n",
      "[eval]:  82%|████████▏ | 74/90 [00:15<00:03,  4.81it/s]\u001b[A\n",
      "[eval]:  83%|████████▎ | 75/90 [00:15<00:03,  4.36it/s]\u001b[A\n",
      "[eval]:  84%|████████▍ | 76/90 [00:16<00:02,  4.97it/s]\u001b[A\n",
      "[eval]:  86%|████████▌ | 77/90 [00:16<00:02,  4.51it/s]\u001b[A\n",
      "[eval]:  87%|████████▋ | 78/90 [00:16<00:02,  4.85it/s]\u001b[A\n",
      "[eval]:  88%|████████▊ | 79/90 [00:16<00:02,  4.45it/s]\u001b[A\n",
      "[eval]:  89%|████████▉ | 80/90 [00:16<00:02,  4.82it/s]\u001b[A\n",
      "[eval]:  90%|█████████ | 81/90 [00:17<00:02,  4.20it/s]\u001b[A\n",
      "[eval]:  91%|█████████ | 82/90 [00:17<00:01,  4.66it/s]\u001b[A\n",
      "[eval]:  92%|█████████▏| 83/90 [00:17<00:01,  4.18it/s]\u001b[A\n",
      "[eval]:  93%|█████████▎| 84/90 [00:17<00:01,  4.59it/s]\u001b[A\n",
      "[eval]:  94%|█████████▍| 85/90 [00:18<00:01,  4.22it/s]\u001b[A\n",
      "[eval]:  96%|█████████▌| 86/90 [00:18<00:00,  4.73it/s]\u001b[A\n",
      "[eval]:  97%|█████████▋| 87/90 [00:18<00:00,  4.24it/s]\u001b[A\n",
      "[eval]:  98%|█████████▊| 88/90 [00:18<00:00,  4.87it/s]\u001b[A\n",
      "[eval]: 100%|██████████| 90/90 [00:18<00:00,  4.74it/s]\u001b[A\n",
      "[train]:   0%|          | 50/500000 [01:35<76:42:41,  1.81it/s] \n",
      "[eval]:   0%|          | 0/90 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "[eval]:   1%|          | 1/90 [00:00<00:58,  1.51it/s]\u001b[A\n",
      "[eval]:   2%|▏         | 2/90 [00:00<00:32,  2.74it/s]\u001b[A\n",
      "[eval]:   3%|▎         | 3/90 [00:01<00:29,  2.98it/s]\u001b[A\n",
      "[eval]:   4%|▍         | 4/90 [00:01<00:22,  3.75it/s]\u001b[A\n",
      "[eval]:   6%|▌         | 5/90 [00:01<00:22,  3.84it/s]\u001b[A\n",
      "[eval]:   7%|▋         | 6/90 [00:01<00:18,  4.46it/s]\u001b[A\n",
      "[eval]:   8%|▊         | 7/90 [00:01<00:20,  4.05it/s]\u001b[A\n",
      "[eval]:   9%|▉         | 8/90 [00:02<00:18,  4.47it/s]\u001b[A\n",
      "[eval]:  10%|█         | 9/90 [00:02<00:19,  4.24it/s]\u001b[A\n",
      "[eval]:  11%|█         | 10/90 [00:02<00:17,  4.66it/s]\u001b[A\n",
      "[eval]:  12%|█▏        | 11/90 [00:02<00:18,  4.35it/s]\u001b[A\n",
      "[eval]:  13%|█▎        | 12/90 [00:03<00:16,  4.72it/s]\u001b[A\n",
      "[eval]:  14%|█▍        | 13/90 [00:03<00:18,  4.14it/s]\u001b[A\n",
      "[eval]:  16%|█▌        | 14/90 [00:03<00:16,  4.72it/s]\u001b[A\n",
      "[eval]:  17%|█▋        | 15/90 [00:03<00:17,  4.17it/s]\u001b[A\n",
      "[eval]:  18%|█▊        | 16/90 [00:03<00:16,  4.62it/s]\u001b[A\n",
      "[eval]:  19%|█▉        | 17/90 [00:04<00:17,  4.28it/s]\u001b[A\n",
      "[eval]:  20%|██        | 18/90 [00:04<00:15,  4.73it/s]\u001b[A\n",
      "[eval]:  21%|██        | 19/90 [00:04<00:14,  4.89it/s]\u001b[A\n",
      "[eval]:  22%|██▏       | 20/90 [00:04<00:13,  5.30it/s]\u001b[A\n",
      "[eval]:  23%|██▎       | 21/90 [00:04<00:13,  4.96it/s]\u001b[A\n",
      "[eval]:  24%|██▍       | 22/90 [00:05<00:12,  5.44it/s]\u001b[A\n",
      "[eval]:  26%|██▌       | 23/90 [00:05<00:13,  4.99it/s]\u001b[A\n",
      "[eval]:  27%|██▋       | 24/90 [00:05<00:12,  5.32it/s]\u001b[A\n",
      "[eval]:  28%|██▊       | 25/90 [00:05<00:13,  4.87it/s]\u001b[A\n",
      "[eval]:  29%|██▉       | 26/90 [00:05<00:11,  5.40it/s]\u001b[A\n",
      "[eval]:  30%|███       | 27/90 [00:06<00:12,  4.91it/s]\u001b[A\n",
      "[eval]:  31%|███       | 28/90 [00:06<00:11,  5.48it/s]\u001b[A\n",
      "[eval]:  32%|███▏      | 29/90 [00:06<00:12,  5.00it/s]\u001b[A\n",
      "[eval]:  33%|███▎      | 30/90 [00:06<00:11,  5.30it/s]\u001b[A\n",
      "[eval]:  34%|███▍      | 31/90 [00:06<00:11,  5.07it/s]\u001b[A\n",
      "[eval]:  36%|███▌      | 32/90 [00:07<00:10,  5.40it/s]\u001b[A\n",
      "[eval]:  37%|███▋      | 33/90 [00:07<00:11,  5.01it/s]\u001b[A\n",
      "[eval]:  38%|███▊      | 34/90 [00:07<00:10,  5.52it/s]\u001b[A\n",
      "[eval]:  39%|███▉      | 35/90 [00:07<00:10,  5.02it/s]\u001b[A\n",
      "[eval]:  40%|████      | 36/90 [00:07<00:10,  5.37it/s]\u001b[A\n",
      "[eval]:  41%|████      | 37/90 [00:08<00:10,  4.91it/s]\u001b[A\n",
      "[eval]:  42%|████▏     | 38/90 [00:08<00:09,  5.40it/s]\u001b[A\n",
      "[eval]:  43%|████▎     | 39/90 [00:08<00:10,  4.80it/s]\u001b[A\n",
      "[eval]:  44%|████▍     | 40/90 [00:08<00:09,  5.09it/s]\u001b[A\n",
      "[eval]:  46%|████▌     | 41/90 [00:08<00:10,  4.65it/s]\u001b[A\n",
      "[eval]:  47%|████▋     | 42/90 [00:09<00:09,  5.09it/s]\u001b[A\n",
      "[eval]:  48%|████▊     | 43/90 [00:09<00:10,  4.47it/s]\u001b[A\n",
      "[eval]:  49%|████▉     | 44/90 [00:09<00:09,  4.93it/s]\u001b[A\n",
      "[eval]:  50%|█████     | 45/90 [00:09<00:09,  4.54it/s]\u001b[A\n",
      "[eval]:  51%|█████     | 46/90 [00:09<00:08,  4.90it/s]\u001b[A\n",
      "[eval]:  52%|█████▏    | 47/90 [00:10<00:09,  4.48it/s]\u001b[A\n",
      "[eval]:  53%|█████▎    | 48/90 [00:10<00:08,  4.75it/s]\u001b[A\n",
      "[eval]:  54%|█████▍    | 49/90 [00:10<00:09,  4.51it/s]\u001b[A\n",
      "[eval]:  56%|█████▌    | 50/90 [00:10<00:08,  4.72it/s]\u001b[A\n",
      "[eval]:  57%|█████▋    | 51/90 [00:11<00:09,  4.28it/s]\u001b[A\n",
      "[eval]:  58%|█████▊    | 52/90 [00:11<00:08,  4.75it/s]\u001b[A\n",
      "[eval]:  59%|█████▉    | 53/90 [00:11<00:08,  4.50it/s]\u001b[A\n",
      "[eval]:  60%|██████    | 54/90 [00:11<00:07,  4.85it/s]\u001b[A\n",
      "[eval]:  61%|██████    | 55/90 [00:11<00:08,  4.24it/s]\u001b[A\n",
      "[eval]:  62%|██████▏   | 56/90 [00:12<00:07,  4.63it/s]\u001b[A\n",
      "[eval]:  63%|██████▎   | 57/90 [00:12<00:07,  4.65it/s]\u001b[A\n",
      "[eval]:  64%|██████▍   | 58/90 [00:12<00:06,  5.21it/s]\u001b[A\n",
      "[eval]:  66%|██████▌   | 59/90 [00:12<00:06,  4.67it/s]\u001b[A\n",
      "[eval]:  67%|██████▋   | 60/90 [00:12<00:05,  5.04it/s]\u001b[A\n",
      "[eval]:  68%|██████▊   | 61/90 [00:13<00:05,  5.32it/s]\u001b[A\n",
      "[eval]:  69%|██████▉   | 62/90 [00:13<00:05,  5.48it/s]\u001b[A\n",
      "[eval]:  70%|███████   | 63/90 [00:13<00:05,  5.08it/s]\u001b[A\n",
      "[eval]:  71%|███████   | 64/90 [00:13<00:04,  5.35it/s]\u001b[A\n",
      "[eval]:  72%|███████▏  | 65/90 [00:13<00:05,  4.79it/s]\u001b[A\n",
      "[eval]:  73%|███████▎  | 66/90 [00:14<00:04,  5.39it/s]\u001b[A\n",
      "[eval]:  74%|███████▍  | 67/90 [00:14<00:04,  4.80it/s]\u001b[A\n",
      "[eval]:  76%|███████▌  | 68/90 [00:14<00:04,  5.31it/s]\u001b[A\n",
      "[eval]:  77%|███████▋  | 69/90 [00:14<00:04,  4.53it/s]\u001b[A\n",
      "[eval]:  78%|███████▊  | 70/90 [00:14<00:03,  5.15it/s]\u001b[A\n",
      "[eval]:  79%|███████▉  | 71/90 [00:15<00:04,  4.70it/s]\u001b[A\n",
      "[eval]:  80%|████████  | 72/90 [00:15<00:03,  4.87it/s]\u001b[A\n",
      "[eval]:  81%|████████  | 73/90 [00:15<00:03,  4.62it/s]\u001b[A\n",
      "[eval]:  82%|████████▏ | 74/90 [00:15<00:03,  5.07it/s]\u001b[A\n",
      "[eval]:  83%|████████▎ | 75/90 [00:15<00:03,  4.52it/s]\u001b[A\n",
      "[eval]:  84%|████████▍ | 76/90 [00:16<00:02,  5.00it/s]\u001b[A\n",
      "[eval]:  86%|████████▌ | 77/90 [00:16<00:03,  4.32it/s]\u001b[A\n",
      "[eval]:  87%|████████▋ | 78/90 [00:16<00:02,  4.82it/s]\u001b[A\n",
      "[eval]:  88%|████████▊ | 79/90 [00:16<00:02,  4.36it/s]\u001b[A\n",
      "[eval]:  89%|████████▉ | 80/90 [00:17<00:02,  4.81it/s]\u001b[A\n",
      "[eval]:  90%|█████████ | 81/90 [00:17<00:01,  4.66it/s]\u001b[A\n",
      "[eval]:  91%|█████████ | 82/90 [00:17<00:01,  5.10it/s]\u001b[A\n",
      "[eval]:  92%|█████████▏| 83/90 [00:17<00:01,  4.79it/s]\u001b[A\n",
      "[eval]:  93%|█████████▎| 84/90 [00:17<00:01,  5.05it/s]\u001b[A\n",
      "[eval]:  94%|█████████▍| 85/90 [00:18<00:01,  4.80it/s]\u001b[A\n",
      "[eval]:  96%|█████████▌| 86/90 [00:18<00:00,  5.07it/s]\u001b[A\n",
      "[eval]:  97%|█████████▋| 87/90 [00:18<00:00,  4.84it/s]\u001b[A\n",
      "[eval]:  98%|█████████▊| 88/90 [00:18<00:00,  5.37it/s]\u001b[A\n",
      "[eval]: 100%|██████████| 90/90 [00:18<00:00,  4.76it/s]\u001b[A\n",
      "[train]:   0%|          | 60/500000 [01:57<77:11:16,  1.80it/s] \n",
      "[eval]:   0%|          | 0/90 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "[eval]:   1%|          | 1/90 [00:00<00:51,  1.72it/s]\u001b[A\n",
      "[eval]:   2%|▏         | 2/90 [00:00<00:29,  3.01it/s]\u001b[A\n",
      "[eval]:   3%|▎         | 3/90 [00:00<00:24,  3.55it/s]\u001b[A\n",
      "[eval]:   4%|▍         | 4/90 [00:01<00:19,  4.31it/s]\u001b[A\n",
      "[eval]:   6%|▌         | 5/90 [00:01<00:20,  4.22it/s]\u001b[A\n",
      "[eval]:   7%|▋         | 6/90 [00:01<00:17,  4.80it/s]\u001b[A\n",
      "[eval]:   8%|▊         | 7/90 [00:01<00:18,  4.38it/s]\u001b[A\n",
      "[eval]:   9%|▉         | 8/90 [00:01<00:16,  4.93it/s]\u001b[A\n",
      "[eval]:  10%|█         | 9/90 [00:02<00:17,  4.59it/s]\u001b[A\n",
      "[eval]:  11%|█         | 10/90 [00:02<00:15,  5.04it/s]\u001b[A\n",
      "[eval]:  12%|█▏        | 11/90 [00:02<00:16,  4.66it/s]\u001b[A\n",
      "[eval]:  13%|█▎        | 12/90 [00:02<00:15,  5.02it/s]\u001b[A\n",
      "[eval]:  14%|█▍        | 13/90 [00:03<00:16,  4.76it/s]\u001b[A\n",
      "[eval]:  16%|█▌        | 14/90 [00:03<00:14,  5.20it/s]\u001b[A\n",
      "[eval]:  17%|█▋        | 15/90 [00:03<00:15,  4.87it/s]\u001b[A\n",
      "[eval]:  18%|█▊        | 16/90 [00:03<00:13,  5.32it/s]\u001b[A\n",
      "[eval]:  19%|█▉        | 17/90 [00:03<00:14,  4.98it/s]\u001b[A\n",
      "[eval]:  20%|██        | 18/90 [00:03<00:13,  5.20it/s]\u001b[A\n",
      "[eval]:  21%|██        | 19/90 [00:04<00:14,  4.91it/s]\u001b[A\n",
      "[eval]:  22%|██▏       | 20/90 [00:04<00:13,  5.23it/s]\u001b[A\n",
      "[eval]:  23%|██▎       | 21/90 [00:04<00:13,  4.97it/s]\u001b[A\n",
      "[eval]:  24%|██▍       | 22/90 [00:04<00:12,  5.34it/s]\u001b[A\n",
      "[eval]:  26%|██▌       | 23/90 [00:04<00:13,  5.01it/s]\u001b[A\n",
      "[eval]:  27%|██▋       | 24/90 [00:05<00:12,  5.36it/s]\u001b[A\n",
      "[eval]:  28%|██▊       | 25/90 [00:05<00:13,  4.93it/s]\u001b[A\n",
      "[eval]:  29%|██▉       | 26/90 [00:05<00:12,  5.20it/s]\u001b[A\n",
      "[eval]:  30%|███       | 27/90 [00:05<00:13,  4.73it/s]\u001b[A\n",
      "[eval]:  31%|███       | 28/90 [00:05<00:12,  4.95it/s]\u001b[A\n",
      "[eval]:  32%|███▏      | 29/90 [00:06<00:13,  4.46it/s]\u001b[A\n",
      "[eval]:  33%|███▎      | 30/90 [00:06<00:12,  4.98it/s]\u001b[A\n",
      "[eval]:  34%|███▍      | 31/90 [00:06<00:13,  4.50it/s]\u001b[A\n",
      "[eval]:  36%|███▌      | 32/90 [00:06<00:12,  4.83it/s]\u001b[A\n",
      "[eval]:  37%|███▋      | 33/90 [00:07<00:12,  4.55it/s]\u001b[A\n",
      "[eval]:  38%|███▊      | 34/90 [00:07<00:11,  4.99it/s]\u001b[A\n",
      "[eval]:  39%|███▉      | 35/90 [00:07<00:11,  4.70it/s]\u001b[A\n",
      "[eval]:  40%|████      | 36/90 [00:07<00:10,  4.98it/s]\u001b[A\n",
      "[eval]:  41%|████      | 37/90 [00:07<00:12,  4.21it/s]\u001b[A\n",
      "[eval]:  42%|████▏     | 38/90 [00:08<00:10,  4.73it/s]\u001b[A\n",
      "[eval]:  43%|████▎     | 39/90 [00:08<00:11,  4.57it/s]\u001b[A\n",
      "[eval]:  44%|████▍     | 40/90 [00:08<00:09,  5.02it/s]\u001b[A\n",
      "[eval]:  46%|████▌     | 41/90 [00:08<00:10,  4.89it/s]\u001b[A\n",
      "[eval]:  47%|████▋     | 42/90 [00:08<00:09,  5.17it/s]\u001b[A\n",
      "[eval]:  48%|████▊     | 43/90 [00:09<00:09,  4.82it/s]\u001b[A\n",
      "[eval]:  49%|████▉     | 44/90 [00:09<00:08,  5.24it/s]\u001b[A\n",
      "[eval]:  50%|█████     | 45/90 [00:09<00:09,  4.55it/s]\u001b[A\n",
      "[eval]:  51%|█████     | 46/90 [00:09<00:08,  5.01it/s]\u001b[A\n",
      "[eval]:  52%|█████▏    | 47/90 [00:10<00:09,  4.67it/s]\u001b[A\n",
      "Traceback (most recent call last):\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x155550312d90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mntcephfs/lab_data/shoinoue/miniconda3/envs/cuhk/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trainer.run()\n",
    "finally:\n",
    "    trainer.save_checkpoint(\n",
    "        os.path.join(config[\"outdir\"], f\"checkpoint-{trainer.steps}steps.pkl\")\n",
    "    )\n",
    "    logging.info(f\"Successfully saved checkpoint @ {trainer.steps}steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5040d2f-3e92-4863-81c7-58641b37e4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296def8-33de-4f46-a931-f7effb21c7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
