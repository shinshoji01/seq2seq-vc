{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a391f7-cb4e-4117-932f-b6bc2a2b78bc",
   "metadata": {},
   "source": [
    "- Utterance-level representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88704b-d9fd-4400-b580-bacef702eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Hindi\"\n",
    "text = f\"\"\"I would like you to output a similar pronunciation of the given English using the target language.\n",
    "For example, assuming the English text is \"Author of the danger trail Philip Steels etc\".\n",
    "The phoneme sequence is \"ˈɔːθɚɹ ʌvðə dˈeɪndʒɚ tɹˈeɪl fˈɪlɪp stˈiːlz ɛtsˈɛtɹə\".\n",
    "The expected Japanese output is \"オーサー・オブ・ザ・デンジャー・トレイル・フィリップ・スティル・エトセトラ。\".\n",
    "The expected Hindi output is \"औथर ऑफ द डेंजर ट्रेल फिलिप स्टिल एट सेटरा\".\n",
    "\n",
    "Now, I would like you to find a similar pronunciation of \"I am playing a single hand in what looks like a losing game.\" using {language} characters.\n",
    "The phoneme sequence is \"aɪɐm plˈeɪɪŋ ɐ sˈɪŋɡəl hˈænd ɪn wˌʌt lˈʊks lˈaɪk ɐ lˈuːzɪŋ ɡˈeɪm\".\n",
    "Please represent the phoneme sequence using {language} characters.\n",
    "\n",
    "All the responses should be in a JSON format as follows:\n",
    "{{\n",
    "\"English text\":[English text],\n",
    "\"phoneme sequence\":[phoneme sequence],\n",
    "\"{language} characters\":[phoneme sequence represented by {language} characters],\n",
    "}}\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1be80-0820-4915-9765-b9d920337e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"English\"\n",
    "text = f\"\"\"I would like you to output a similar pronunciation of the given Japanese using the target language (transliteration).\n",
    "For example, assuming the Japanese text is \"Author of the danger trail Philip Steels etc\".\n",
    "\n",
    "Now, I would like you to find a similar pronunciation of \"こんにちは、私の名前はツミキです。\" using {language} characters.\n",
    "Please represent the text using {language} characters.\n",
    "\n",
    "All the responses should be in a JSON format as follows:\n",
    "{{\n",
    "\"Japanese text\":[Japanese text],\n",
    "\"{language} characters\":[Japanese text represented by {language} characters],\n",
    "}}\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efe7f3-1fa5-4847-a2b4-7f7cefedd6c4",
   "metadata": {},
   "source": [
    "- [target language] phoneme sequence -> English sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ebefe-b089-48fe-b77f-cc3ba895adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"ˈɔːtʰəɾ ˈɔpʰ dˈə ɖˈẽːɟəɾ ʈɾˈeːl pʰˈɪlɪp sʈˈɪl ˈeːʈ sˈeːʈɾˌaː dˈʌɳɖ\"\n",
    "text = f\"\"\"Your task is to generate the corresponding English sentence from the phoneme sequence in IPA format.\n",
    "For example, assuming the phoneme sequence is \"aɪɐm plˈeɪɪŋ ɐ sˈɪŋɡəl hˈænd ɪn wˌʌt lˈʊks lˈaɪk ɐ lˈuːzɪŋ ɡˈeɪm\"\n",
    "Then, the expected English text is \"I am playing a single hand in what looks like a losing game\".\n",
    "Here, you task is to generate the English sentence of the phoneme sequence of Hindi sentence, delimited by triple backticks.\n",
    "\n",
    "```\n",
    "{sequence}\n",
    "```\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386348f-ff65-4890-a5df-af176e3a52a6",
   "metadata": {},
   "source": [
    "- generate several word-level representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08fceb-7482-49e3-9e25-a0d119ac22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonemizer import phonemize\n",
    "import random\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804d305-e556-4a7c-a383-d2b2cbe9e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "The following is the example in Japanese.\n",
    "{{\n",
    "  \"I\": {{\n",
    "    \"phonemes\": \"ˈaɪ\",\n",
    "    \"choices\": [\"アィ\", \"アイ\", \"アーイ\"],\n",
    "    \"similarity order\": [\"アイ\", \"アィ\", \"\"],\n",
    "    }},\n",
    "  \"love\": {{\n",
    "    \"phonemes\": \"lˈʌv\",\n",
    "    \"choices\": [\"प्यार\", \"इश्क़\", \"मोहब्बत\"],\n",
    "    \"similarity order\": [\"प्यार\", \"मोहब्बत\", \"इश्क़\"],\n",
    "    }},\n",
    "  \"you\": {{\n",
    "    \"phonemes\": \"juː\",\n",
    "    \"choices\": [\"तुझको\", \"तुझे\", \"तुम\"],\n",
    "    \"similarity order\": [\"तुम\", \"तुझे\", \"तुझको\"],\n",
    "    }},\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc99e87-e86e-4f3c-b538-a13d9ff16f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Author of the danger trail philip steels et cetera\"\n",
    "# sentence = \"I am playing a single hand in what looks like a losing game\"\n",
    "# sentence = \"I love you\"\n",
    "words = sentence.split()\n",
    "# phonemized = [phonemize(word, language='en-us', backend='espeak', with_stress=True).split()[0] for word in words]\n",
    "shfflephonemized = phonemized\n",
    "# random.shuffle(shfflephonemized)\n",
    "# language = \"Russian\"\n",
    "# language = \"Hindi\"\n",
    "language = \"Swedish\"\n",
    "\n",
    "start = f\"\"\"Can you provide me with three {language} words to represent the phoneme sequences delimited by triple backticks. \n",
    "For example, in Japanese, \"Trail (tɹˈeɪl)\" is expected to have Japanese representation of \"トレイル\"; where \"'\" in phonemes represents the stress point of the word. \n",
    "Here, your task is to provide me with three {language} words that can replace the phoneme senquences, delimited by triple backticks.\n",
    "Please focus on phonetically similar characters instead of similar characters in terms of the meaning.\n",
    "The expected output should be in JSON format. \n",
    "You can first list three possible choices of the words and then re-order them in order of the similarity of the pronunciation. \n",
    "The following is the example in Hindi language.\n",
    "{{\n",
    "  \"I\": {{\n",
    "    \"phonemes\": \"ˈaɪ\",\n",
    "    \"choices\": [\"आई\", \"ऐ\", \"आई\"],\n",
    "    \"similarity order\": [\"आई\", \"ऐ\", \"आई\"]\n",
    "  }},\n",
    "  \"love\": {{\n",
    "    \"phonemes\": \"lˈʌv\",\n",
    "    \"choices\": [\"लव\", \"लव\", \"लव\"],\n",
    "    \"similarity order\": [\"लव\", \"लव\", \"लव\"]\n",
    "  }},\n",
    "  \"you\": {{\n",
    "    \"phonemes\": \"juː\",\n",
    "    \"choices\": [\"यू\", \"यू\", \"यू\"],\n",
    "    \"similarity order\": [\"यू\", \"यू\", \"यू\"]\n",
    "  }},\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "for p, ph in enumerate(shfflephonemized):\n",
    "    start += f\"{words[p]}: {ph}\\n\"\n",
    "start = start[:-1]\n",
    "start += f\"\"\"\n",
    "```\n",
    "Again, the responses should be in a JSON format and sort them in order of the similarity to each phoneme sequence.\n",
    "{{\n",
    "\"\"\"\n",
    "for p, ph in enumerate(shfflephonemized):\n",
    "    # start += f\"\"\"  \"{ph}\": [1st most similar {language} word, 2nd most similar {language} word, 3rd most similar {language} word],\\n\"\"\"\n",
    "    # start += f\"\"\"  \"{ph}\": [1st {language} characters, 2nd {language} characters, 3rd {language} characters],\\n\"\"\"\n",
    "    start += f\"\"\"  \"{words[p]}\": {{\n",
    "    \"phonemes\": \"{ph}\",\n",
    "    \"choices\": [`1st choices of {language} characters`, `2nd choices of {language} characters`, `3rd choices of {language} characters`],\n",
    "    \"similarity order\": [`1st most similar {language} characters`, `2nd most similar {language} characters`, `3rd most similar {language} characters`],\n",
    "    }},\\n\"\"\"\n",
    "start = start[:] + \"}\"\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c61b8-afa0-4693-b2fa-052a7f4645da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai\n",
    "from openai import OpenAI\n",
    "api_key = \"sk-ANuLBmSVZUkf8I308b17C775Ce464c7dA06dF119E9A29fE3\"\n",
    "api_base = \"https://api.ai-gaochao.cn/v1\"\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "def get_response(text):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo-1106\",\n",
    "      # model=\"gpt-3.5-turbo-instruct\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffafb3f9-287e-4f3e-a505-cab34aa72226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_response(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9874a93-15a3-495e-9991-b63f14c7bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd80ea-9380-4eac-9085-925ab9b2a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [\n",
    "    eval(response[response.index(\"{\"):-1*response[::-1].index(\"}\")]) if response[-1]!=\"}\" else eval(response[response.index(\"{\"):]),\n",
    "]\n",
    "dirs = []\n",
    "for a in a_list:\n",
    "    a = {key: a[key] for key in words}\n",
    "    # a = {key: a[key] for key in shfflephonemized}\n",
    "    dirs += [a]\n",
    "for i in range(len(dirs)):\n",
    "    for key in dirs[i]:\n",
    "        newlist = []\n",
    "        for j in range(len(dirs[i][key][\"similarity order\"])):\n",
    "            newlist += [dirs[i][key][\"similarity order\"][j]]*(3-j)\n",
    "        dirs[i][key][\"similarity order\"] = newlist\n",
    "data = {key: [element for i in range(len(dirs)) for element in dirs[i][key][\"similarity order\"]] for key in dirs[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134239d-05ec-4a49-8a8b-9b0b66a66a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 2\n",
    "arrays = []\n",
    "counts = []\n",
    "for i in range(len(data)):\n",
    "    c = collections.Counter(data[list(data.keys())[i]])\n",
    "    if len(c)>1:\n",
    "        df = pd.DataFrame(c.items(), columns=[\"phonemes\", \"count\"]).sort_values(\"count\", ascending=False).values\n",
    "        arrays += [list(df[:rank,0])]\n",
    "        counts += [list(df[:rank,1])]\n",
    "    else:\n",
    "        arrays += [list(c.keys())*2]\n",
    "        counts += [list(c.values())*2]\n",
    "arrays = np.array(arrays).T\n",
    "for i in range(rank):\n",
    "    print(\" \".join(list(arrays[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8f1ce-896a-4dd9-a760-fcb0345f7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(data.keys())[0]\n",
    "c = collections.Counter(data[key])\n",
    "print(key)\n",
    "print(\" \".join(list(c.keys())))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818366d6-7767-4454-b431-717c013c0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [\n",
    "    {\n",
    "        \"Author\": [\"오토\", \"오브\", \"더\"],\n",
    "        \"of\": [\"오프\", \"오브\", \"더\"],\n",
    "        \"the\": [\"디\", \"더\", \"덴저\"],\n",
    "        \"danger\": [\"데인저\", \"덴저\", \"덴자\"],\n",
    "        \"trail\": [\"트레일\", \"트렐\", \"트래\"],\n",
    "        \"philip\": [\"필립\", \"필립스\", \"필림\"],\n",
    "        \"steels\": [\"스틸스\", \"스틸\", \"스틸즈\"],\n",
    "        \"et\": [\"엣\", \"에티\", \"엣또\"],\n",
    "        \"cetera\": [\"세테라\", \"쎄테라\", \"쎄터라\"]\n",
    "    },\n",
    "    {\n",
    "        \"Author\": [\"오프어\", \"오브어\", \"오브더\"],\n",
    "        \"of\": [\"오프\", \"어프\", \"어브\"],\n",
    "        \"the\": [\"디\", \"더\", \"지\"],\n",
    "        \"danger\": [\"데인저\", \"대인저\", \"덴저\"],\n",
    "        \"trail\": [\"트레일\", \"트레이일\", \"테일\"],\n",
    "        \"philip\": [\"필립\", \"피립\", \"피릅\"],\n",
    "        \"steels\": [\"스틸스\", \"스틸즈\", \"스틸쓰\"],\n",
    "        \"et\": [\"엣\", \"이트\", \"에트\"],\n",
    "        \"cetera\": [\"세테라\", \"세테라\", \"세테라\"]\n",
    "    },\n",
    "    {\n",
    "        \"Author\": [\"오파\", \"어터\", \"오설\"],\n",
    "        \"of\": [\"오프\", \"어프\", \"오브\"],\n",
    "        \"the\": [\"디\", \"더\", \"더\"],\n",
    "        \"danger\": [\"데인저\", \"대인저\", \"다인저\"],\n",
    "        \"trail\": [\"트레일\", \"테일\", \"틀레\"],\n",
    "        \"philip\": [\"필립\", \"피립\", \"펠립\"],\n",
    "        \"steels\": [\"스틸스\", \"스틸즈\", \"스틸츠\"],\n",
    "        \"et\": [\"엣\", \"에트\", \"이트\"],\n",
    "        \"cetera\": [\"세테라\", \"체테라\", \"세테라\"]\n",
    "    }\n",
    "]\n",
    "dirs = []\n",
    "for a in a_list:\n",
    "    a = {key: a[key] for key in words}\n",
    "    dirs += [a]\n",
    "for i in range(len(dirs)):\n",
    "    for key in dirs[i]:\n",
    "        newlist = []\n",
    "        for j in range(len(dirs[i][key])):\n",
    "            newlist += [dirs[i][key][j]]*(3-j)\n",
    "        dirs[i][key] = newlist\n",
    "data = {key: [element for i in range(len(dirs)) for element in dirs[i][key]] for key in dirs[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117a34e-1a2a-4055-bbd2-a4814adf3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [\n",
    "{\n",
    "  \"Author\": [\"オーサー\", \"オーソー\", \"オウザー\"],\n",
    "  \"of\": [\"オヴ\", \"オーヴ\", \"オフ\"],\n",
    "  \"the\": [\"ザ\", \"ザ・\", \"ゼ\"],\n",
    "  \"danger\": [\"デンジャー\", \"ダンジャー\", \"デンガー\"],\n",
    "  \"trail\": [\"トレイル\", \"トレール\", \"トライル\"],\n",
    "  \"philip\": [\"フィリップ\", \"フィリップ\", \"フィリプ\"],\n",
    "  \"steels\": [\"スティールズ\", \"スティールズ\", \"ステールズ\"],\n",
    "  \"et\": [\"エト\", \"エット\", \"イート\"],\n",
    "  \"cetera\": [\"セテラ\", \"セテラ\", \"セテラ\"]\n",
    "},\n",
    "{\n",
    "  \"Author\": [\"ˈɔːθɚ\", \"オーサー\", \"オーソー\"],\n",
    "  \"of\": [\"ʌv\", \"オブ\", \"オヴ\"],\n",
    "  \"the\": [\"ðə\", \"ザ\", \"ザ\"],\n",
    "  \"danger\": [\"dˈeɪndʒɚ\", \"デインジャー\", \"デンジャー\"],\n",
    "  \"trail\": [\"tɹˈeɪl\", \"トレイル\", \"トレール\"],\n",
    "  \"philip\": [\"fˈɪlɪp\", \"フィリップ\", \"フィリプ\"],\n",
    "  \"steels\": [\"stˈiːlz\", \"スティールズ\", \"ステールズ\"],\n",
    "  \"et\": [\"ˈɛt\", \"エト\", \"エット\"],\n",
    "  \"cetera\": [\"sˈɛɾɚɹə\", \"セテラ\", \"セテラ\"]\n",
    "},\n",
    "{\n",
    "  \"Author\": [\"オーサー\", \"オウサー\", \"アウサー\"],\n",
    "  \"of\": [\"オブ\", \"オヴ\", \"オッブ\"],\n",
    "  \"the\": [\"ザ\", \"ゼ\", \"テ\"],\n",
    "  \"danger\": [\"デインジャー\", \"ダンジャー\", \"ダンゲル\"],\n",
    "  \"trail\": [\"トレイル\", \"トライル\", \"テイル\"],\n",
    "  \"philip\": [\"フィリップ\", \"フィリプ\", \"ピリップ\"],\n",
    "  \"steels\": [\"スティールズ\", \"ステルズ\", \"スチールズ\"],\n",
    "  \"et\": [\"エト\", \"エッ\", \"エ\"],\n",
    "  \"cetera\": [\"セテラ\", \"セテラー\", \"セテッラ\"]\n",
    "},\n",
    "]\n",
    "dirs = []\n",
    "for a in a_list:\n",
    "    a = {key: a[key] for key in words}\n",
    "    dirs += [a]\n",
    "for i in range(len(dirs)):\n",
    "    for key in dirs[i]:\n",
    "        newlist = []\n",
    "        for j in range(len(dirs[i][key])):\n",
    "            ph = dirs[i][key][j]\n",
    "            if ph==phonemized[words.index(key)]:\n",
    "                continue\n",
    "            newlist += [ph]*(3-j)\n",
    "        dirs[i][key] = newlist\n",
    "data = {key: [element for i in range(len(dirs)) for element in dirs[i][key]] for key in dirs[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9317dc-06c1-4416-8053-ff0a41f673b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [\n",
    "    {\n",
    "        \"Author\": {\n",
    "            \"choices\": [\"ऑथर\", \"आथर\", \"आउथर\"],\n",
    "            \"similarity order\": [\"आथर\", \"ऑथर\", \"आउथर\"]\n",
    "        },\n",
    "        \"of\": {\n",
    "            \"choices\": [\"अफ़\", \"ऑफ़\", \"आफ़\"],\n",
    "            \"similarity order\": [\"अफ़\", \"आफ़\", \"ऑफ़\"]\n",
    "        },\n",
    "        \"the\": {\n",
    "            \"choices\": [\"द\", \"दा\", \"ध\"],\n",
    "            \"similarity order\": [\"द\", \"दा\", \"ध\"]\n",
    "        },\n",
    "        \"danger\": {\n",
    "            \"choices\": [\"डेंजर\", \"डैंजर\", \"डॅन्जर\"],\n",
    "            \"similarity order\": [\"डैंजर\", \"डेंजर\", \"डॅन्जर\"]\n",
    "        },\n",
    "        \"trail\": {\n",
    "            \"choices\": [\"ट्रेल\", \"ट्रेल्स\", \"त्रैल\"],\n",
    "            \"similarity order\": [\"ट्रेल\", \"त्रैल\", \"ट्रेल्स\"]\n",
    "        },\n",
    "        \"philip\": {\n",
    "            \"choices\": [\"फिलिप\", \"फिलिप्स\", \"फिलप\"],\n",
    "            \"similarity order\": [\"फिलिप\", \"फिलप\", \"फिलिप्स\"]\n",
    "        },\n",
    "        \"steels\": {\n",
    "            \"choices\": [\"स्टील्स\", \"स्टील\", \"स्टील्स\"],\n",
    "            \"similarity order\": [\"स्टील्स\", \"स्टील\", \"स्टील्स\"]\n",
    "        },\n",
    "        \"et\": {\n",
    "            \"choices\": [\"इट\", \"इति\", \"ईट\"],\n",
    "            \"similarity order\": [\"ईट\", \"इट\", \"इति\"]\n",
    "        },\n",
    "        \"cetera\": {\n",
    "            \"choices\": [\"सेटेरा\", \"सेटेरा\", \"सेतेरा\"],\n",
    "            \"similarity order\": [\"सेटेरा\", \"सेटेरा\", \"सेतेरा\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"Author\": {\n",
    "            \"choices\": [\"आथर\", \"ऑथर\", \"ऑथर्स\"],\n",
    "            \"similarity order\": [\"आथर\", \"ऑथर\", \"ऑथर्स\"]\n",
    "        },\n",
    "        \"of\": {\n",
    "            \"choices\": [\"अफ\", \"ऑफ\", \"ऑफ्स\"],\n",
    "            \"similarity order\": [\"अफ\", \"ऑफ\", \"ऑफ्स\"]\n",
    "        },\n",
    "        \"the\": {\n",
    "            \"choices\": [\"द\", \"द\", \"द\"],\n",
    "            \"similarity order\": [\"द\", \"द\", \"द\"]\n",
    "        },\n",
    "        \"danger\": {\n",
    "            \"choices\": [\"डैंजर\", \"डैंजर\", \"डैंजर्स\"],\n",
    "            \"similarity order\": [\"डैंजर\", \"डैंजर\", \"डैंजर्स\"]\n",
    "        },\n",
    "        \"trail\": {\n",
    "            \"choices\": [\"ट्रेल\", \"ट्रेल\", \"ट्रेल्स\"],\n",
    "            \"similarity order\": [\"ट्रेल\", \"ट्रेल\", \"ट्रेल्स\"]\n",
    "        },\n",
    "        \"philip\": {\n",
    "            \"choices\": [\"फिलिप\", \"फिलिप\", \"फिलिप्स\"],\n",
    "            \"similarity order\": [\"फिलिप\", \"फिलिप\", \"फिलिप्स\"]\n",
    "        },\n",
    "        \"steels\": {\n",
    "            \"choices\": [\"स्टील्स\", \"स्टील्स\", \"स्टील्स\"],\n",
    "            \"similarity order\": [\"स्टील्स\", \"स्टील्स\", \"स्टील्स\"]\n",
    "        },\n",
    "        \"et\": {\n",
    "            \"choices\": [\"एट\", \"ईट\", \"इट\"],\n",
    "            \"similarity order\": [\"एट\", \"ईट\", \"इट\"]\n",
    "        },\n",
    "        \"cetera\": {\n",
    "            \"choices\": [\"सीटेरा\", \"सीटेरा\", \"सीटेरा\"],\n",
    "            \"similarity order\": [\"सीटेरा\", \"सीटेरा\", \"सीटेरा\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"Author\": {\n",
    "            \"choices\": [\"ऑथर\", \"आथर\", \"आउथर\"],\n",
    "            \"similarity order\": [\"ऑथर\", \"आथर\", \"आउथर\"]\n",
    "        },\n",
    "        \"of\": {\n",
    "            \"choices\": [\"अफ\", \"ऑफ\", \"औफ\"],\n",
    "            \"similarity order\": [\"ऑफ\", \"अफ\", \"औफ\"]\n",
    "        },\n",
    "        \"the\": {\n",
    "            \"choices\": [\"द\", \"द\", \"द\"],\n",
    "            \"similarity order\": [\"द\", \"द\", \"द\"]\n",
    "        },\n",
    "        \"danger\": {\n",
    "            \"choices\": [\"डेंजर\", \"डेन्जर\", \"डैंजर\"],\n",
    "            \"similarity order\": [\"डेंजर\", \"डेन्जर\", \"डैंजर\"]\n",
    "        },\n",
    "        \"trail\": {\n",
    "            \"choices\": [\"ट्रेल\", \"ट्रेल\", \"ट्रेल\"],\n",
    "            \"similarity order\": [\"ट्रेल\", \"ट्रेल\", \"ट्रेल\"]\n",
    "        },\n",
    "        \"philip\": {\n",
    "            \"choices\": [\"फिलिप\", \"फिलिप\", \"फिलिप\"],\n",
    "            \"similarity order\": [\"फिलिप\", \"फिलिप\", \"फिलिप\"]\n",
    "        },\n",
    "        \"steels\": {\n",
    "            \"choices\": [\"स्टील्स\", \"स्टील्स\", \"स्टील्स\"],\n",
    "            \"similarity order\": [\"स्टील्स\", \"स्टील्स\", \"स्टील्स\"]\n",
    "        },\n",
    "        \"et\": {\n",
    "            \"choices\": [\"एट\", \"ईट\", \"इट\"],\n",
    "            \"similarity order\": [\"एट\", \"ईट\", \"इट\"]\n",
    "        },\n",
    "        \"cetera\": {\n",
    "            \"choices\": [\"सेटेरा\", \"सेटेरा\", \"सेटेरा\"],\n",
    "            \"similarity order\": [\"सेटेरा\", \"सेटेरा\", \"सेटेरा\"]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "dirs = []\n",
    "for a in a_list:\n",
    "    a = {key: a[key] for key in words}\n",
    "    dirs += [a]\n",
    "for i in range(len(dirs)):\n",
    "    for key in dirs[i]:\n",
    "        newlist = []\n",
    "        for j in range(len(dirs[i][key][\"similarity order\"])):\n",
    "            newlist += [dirs[i][key][\"similarity order\"][j]]*(3-j)\n",
    "        dirs[i][key][\"similarity order\"] = newlist\n",
    "data = {key: [element for i in range(len(dirs)) for element in dirs[i][key][\"similarity order\"]] for key in dirs[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81aa1d4-2a3a-4885-9872-abb9174b83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [\n",
    "    {\n",
    "        \"Author\": {\n",
    "            \"phonemes\": \"ˈɔːθɚ\",\n",
    "            \"choices\": [\"автор\", \"офор\", \"афтар\"],\n",
    "            \"similarity order\": [\"автор\", \"афтар\", \"офор\"]\n",
    "        },\n",
    "        \"of\": {\n",
    "            \"phonemes\": \"ʌv\",\n",
    "            \"choices\": [\"ов\", \"ав\", \"ув\"],\n",
    "            \"similarity order\": [\"ов\", \"ав\", \"ув\"]\n",
    "        },\n",
    "        \"the\": {\n",
    "            \"phonemes\": \"ðə\",\n",
    "            \"choices\": [\"зе\", \"де\", \"те\"],\n",
    "            \"similarity order\": [\"де\", \"зе\", \"те\"]\n",
    "        },\n",
    "        \"danger\": {\n",
    "            \"phonemes\": \"dˈeɪndʒɚ\",\n",
    "            \"choices\": [\"денджер\", \"данджер\", \"дэнджэр\"],\n",
    "            \"similarity order\": [\"денджер\", \"данджер\", \"дэнджэр\"]\n",
    "        },\n",
    "        \"trail\": {\n",
    "            \"phonemes\": \"tɹˈeɪl\",\n",
    "            \"choices\": [\"трэйл\", \"трейл\", \"траил\"],\n",
    "            \"similarity order\": [\"трейл\", \"трэйл\", \"траил\"]\n",
    "        },\n",
    "        \"philip\": {\n",
    "            \"phonemes\": \"fˈɪlɪp\",\n",
    "            \"choices\": [\"филип\", \"пилип\", \"филлип\"],\n",
    "            \"similarity order\": [\"филип\", \"филлип\", \"пилип\"]\n",
    "        },\n",
    "        \"steels\": {\n",
    "            \"phonemes\": \"stˈiːlz\",\n",
    "            \"choices\": [\"стилз\", \"стилс\", \"стелс\"],\n",
    "            \"similarity order\": [\"стилс\", \"стилз\", \"стелс\"]\n",
    "        },\n",
    "        \"et\": {\n",
    "            \"phonemes\": \"ˈɛt\",\n",
    "            \"choices\": [\"эт\", \"ет\", \"ат\"],\n",
    "            \"similarity order\": [\"эт\", \"ет\", \"ат\"]\n",
    "        },\n",
    "        \"cetera\": {\n",
    "            \"phonemes\": \"sˈɛɾɚɹə\",\n",
    "            \"choices\": [\"сетера\", \"цетера\", \"ситера\"],\n",
    "            \"similarity order\": [\"сетера\", \"цетера\", \"ситера\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "]\n",
    "dirs = []\n",
    "for a in a_list:\n",
    "    a = {key: a[key] for key in words}\n",
    "    # a = {key: a[key] for key in shfflephonemized}\n",
    "    dirs += [a]\n",
    "for i in range(len(dirs)):\n",
    "    for key in dirs[i]:\n",
    "        newlist = []\n",
    "        for j in range(len(dirs[i][key][\"similarity order\"])):\n",
    "            newlist += [dirs[i][key][\"similarity order\"][j]]*(3-j)\n",
    "        dirs[i][key][\"similarity order\"] = newlist\n",
    "data = {key: [element for i in range(len(dirs)) for element in dirs[i][key][\"similarity order\"]] for key in dirs[0]}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
