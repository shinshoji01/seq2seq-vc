{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e23fc-3079-4d36-b451-48554c8d55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained.interfaces import foreign_class\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import IPython\n",
    "def play_audio(data, rate):\n",
    "    IPython.display.display(IPython.display.Audio(data=data,rate=rate))\n",
    "\n",
    "# classifier = foreign_class(source=\"Jzuluaga/accent-id-commonaccent_xlsr-en-english\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
    "classifier = foreign_class(source=\"pretrained_models/CustomEncoderWav2vec2Classifier-a72df039c801fa14a1c3226e95ab8c14/\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
    "\n",
    "information = [\n",
    "    [\"ABA\", \"Arabic\", \"M\"],\n",
    "    [\"SKA\", \"Arabic\", \"F\"],\n",
    "    [\"YBAA\", \"Arabic\", \"M\"],\n",
    "    [\"ZHAA\", \"Arabic\", \"F\"],\n",
    "    [\"BWC\", \"Mandarin\", \"M\"],\n",
    "    [\"LXC\", \"Mandarin\", \"F\"],\n",
    "    [\"NCC\", \"Mandarin\", \"F\"],\n",
    "    [\"TXHC\", \"Mandarin\", \"M\"],\n",
    "    [\"ASI\", \"Hindi\", \"M\"],\n",
    "    [\"RRBI\", \"Hindi\", \"M\"],\n",
    "    [\"SVBI\", \"Hindi\", \"F\"],\n",
    "    [\"TNI\", \"Hindi\", \"F\"],\n",
    "    [\"HJK\", \"Korean\", \"F\"],\n",
    "    [\"HKK\", \"Korean\", \"M\"],\n",
    "    [\"YDCK\", \"Korean\", \"F\"],\n",
    "    [\"YKWK\", \"Korean\", \"M\"],\n",
    "    [\"EBVS\", \"Spanish\", \"M\"],\n",
    "    [\"ERMS\", \"Spanish\", \"M\"],\n",
    "    [\"MBMPS\", \"Spanish\", \"F\"],\n",
    "    [\"NJS\", \"Spanish\", \"F\"],\n",
    "    [\"HQTV\", \"Vietnamese\", \"M\"],\n",
    "    [\"PNV\", \"Vietnamese\", \"F\"],\n",
    "    [\"THV\", \"Vietnamese\", \"F\"],\n",
    "    [\"TLV\", \"Vietnamese\", \"M\"],\n",
    "    [\"cmu_us_bdl_arctic\", \"US\", \"M\"],\n",
    "    [\"cmu_us_eey_arctic\", \"US\", \"F\"],\n",
    "    [\"cmu_us_slt_arctic\", \"US\", \"F\"],\n",
    "    [\"cmu_us_rms_arctic\", \"US\", \"M\"],\n",
    "]\n",
    "spk2acc = {info[0]: info[1] for info in information}\n",
    "spk2sex = {info[0]: info[2] for info in information}\n",
    "acc2spk = {key: [] for key in set(list(spk2acc.values()))}\n",
    "sex2spk = {key: [] for key in set(list(spk2sex.values()))}\n",
    "for spk in spk2acc:\n",
    "    acc2spk[spk2acc[spk]] += [spk]\n",
    "    sex2spk[spk2sex[spk]] += [spk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d945c23-be94-416a-a785-2c2567fab2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"./../Dataset/L2-ARCTIC_v5/\"\n",
    "speakers = [os.path.basename(a[:-1]) for a in glob.glob(basedir+\"*/\")]\n",
    "speakers.remove(\"suitcase_corpus\")\n",
    "speakers.sort()\n",
    "speakers_ordered = [a for la in acc2spk for a in acc2spk[la]]\n",
    "fulllist = [os.path.basename(a) for a in glob.glob(basedir + f\"{speakers[4]}/wav/*\")]\n",
    "fulllist.sort()\n",
    "commonfiles = [base for base in fulllist if len(glob.glob(basedir + f\"*/wav/{base}\"))==len(speakers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b72500-db3d-407b-9573-62b5b8fe2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def get_accent_embedding(path, sr=16000):\n",
    "    signal, org_sr = torchaudio.load(path)\n",
    "    signal = torchaudio.functional.resample(signal, orig_freq=org_sr, new_freq=sr)\n",
    "    embeddings =  classifier.encode_batch(signal)\n",
    "    return embeddings[0]\n",
    "\n",
    "def cosine_similarity(e1, e2): # from wespeaker, delete the normalizing part\n",
    "    cosine_score = torch.dot(e1, e2) / (torch.norm(e1) * torch.norm(e2))\n",
    "    cosine_score = cosine_score.item()\n",
    "    return cosine_score\n",
    "\n",
    "def get_similarity_matrix(data, base):\n",
    "    arrays = np.zeros((len(speakers), len(speakers)))\n",
    "    for s1, spk1 in enumerate(speakers_ordered):\n",
    "        for s2, spk2 in enumerate(speakers_ordered):\n",
    "            if s1==s2:\n",
    "                score = np.nan\n",
    "            else:\n",
    "                score = cosine_similarity(data[base][spk1], data[base][spk2])\n",
    "            arrays[s1, s2] = score\n",
    "    spksim = pd.DataFrame(arrays, index=speakers_ordered, columns=speakers_ordered)\n",
    "\n",
    "    step = 4\n",
    "    nsteps = spksim.shape[0]//step\n",
    "    arrays = np.zeros((nsteps, nsteps))\n",
    "    for i in range(nsteps):\n",
    "        for j in range(nsteps):\n",
    "            score = spksim.iloc[i*step:i*step+step, j*step:j*step+step].mean().mean()\n",
    "            arrays[i, j] = score\n",
    "    accsim = pd.DataFrame(arrays, index=list(acc2spk.keys()), columns=list(acc2spk.keys()))\n",
    "    return spksim, accsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed879821-ecc3-425f-bd59-17a7f2027961",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 100\n",
    "\n",
    "data = {}\n",
    "np.random.seed(0)\n",
    "for b, base in enumerate(np.random.choice(commonfiles, sample_num, False)):\n",
    "    data[base] = {}\n",
    "    for s, spk in enumerate(speakers):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"{b+1} / {sample_num}: {base}\")\n",
    "        print(f\"{s+1} / {len(speakers)}: {spk}\")\n",
    "        path = basedir + f\"{spk}/wav/{base}\"\n",
    "        data[base][spk] = get_accent_embedding(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9100dda-e1c5-4920-8ff8-7f0bbf787617",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = list(data.keys())[0]\n",
    "arrays = []\n",
    "for base in data:\n",
    "    spksim, accsim = get_similarity_matrix(data, base)\n",
    "    arrays += [accsim.values]\n",
    "accsim.loc[:] = np.array(arrays).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216c7eb-9fbc-44d1-84bb-a66f084748c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_, max_ = accsim.values.min(), accsim.values.max()\n",
    "def heatmap_color(val):\n",
    "    val = (val-min_) / (max_-min_)*0.7\n",
    "    color = f'background-color: rgba(255, 255, 255, {val});'\n",
    "    return color\n",
    "accsim.style.applymap(heatmap_color)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
